# main.py
import tkinter as tk
from tkinter import scrolledtext, ttk, messagebox, simpledialog, Toplevel
import os
import shutil
import threading
import subprocess
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import re
import time
import webbrowser 
import numpy as np
from datetime import datetime
from PIL import Image, ImageTk, ImageOps  # ì´ë¯¸ì§€ í”„ë¦¬ë·°ìš© (pip install pillow í•„ìš”)
import difflib # ìœ ì‚¬ë„ ì •ë ¬ìš©

import config
import notion_api
import gemini_api
import concept_manager
import concept_sync
# ==================================================================================
# [ì„¤ì •] AI í•´ì„¤ ì˜ì—­ì„ êµ¬ë¶„í•˜ëŠ” ì ˆëŒ€ì ì¸ ê¸°ì¤€ì„ ì…ë‹ˆë‹¤. 
# ì´ ë¬¸ìì—´ì´ ë°œê²¬ë˜ë©´, ì´ ë°‘ì˜ ë‚´ìš©ì€ ë¬´ì¡°ê±´ ì‚­ì œë˜ê³  ìƒˆë¡œìš´ í•´ì„¤ë¡œ êµì²´ë©ë‹ˆë‹¤.
# ==================================================================================
AI_SECTION_MARKER = "\n\n\n---\n## ğŸ¤– AI ìƒì„¸ í•´ì„¤\n"
# ==========================================================
# [Configuration] ì „ì—­ ìƒìˆ˜ ë° ê²½ë¡œ ì„¤ì •
# ==========================================================
ERROR_DIR = os.path.join(config.DRIVE_WATCH_FOLDER, "_ERROR_FILES")
COMPLETED_DIR = os.path.join(config.DRIVE_WATCH_FOLDER, "_COMPLETED")

def ensure_dirs():
    if not os.path.exists(ERROR_DIR): os.makedirs(ERROR_DIR)
    if not os.path.exists(COMPLETED_DIR): os.makedirs(COMPLETED_DIR)


def backup_main_source_phase2():
    backup_dir = os.path.join(os.path.dirname(__file__), "_BACKUP")
    os.makedirs(backup_dir, exist_ok=True)
    backup_path = os.path.join(backup_dir, "main_Backup_Phase2.py")
    try:
        shutil.copy2(__file__, backup_path)
    except Exception:
        pass

# ==========================================================
# [Main Class] MathBot V27 Control Center (Full Integration)
# ==========================================================
class AutoMathBot:
    def __init__(self, root):
        self.root = root
        self.root.title(f"MathBot V27 (The Control Center - Full Logic)")
        self.root.geometry("1600x950") 
        
        # [Data Containers]
        self.md_files = []        
        self.md_contents = []     
        self.md_numbers = []      
        self.search_corpus = []   
        
        self.concept_map = {}     # ì œëª© -> Notion Page ID
        self.history_data = [] 
        
        self.current_preview_image = None # ì´ë¯¸ì§€ ê°ì²´ ìœ ì§€ìš© (GC ë°©ì§€)
        self.current_page_id = None       # í˜„ì¬ ì„ íƒëœ ë¬¸ì œì˜ ë…¸ì…˜ ID
        self.current_problem_file = None  # í˜„ì¬ ì„ íƒëœ ë¬¸ì œ íŒŒì¼ëª…

        ensure_dirs()
        
        # [UI Construction] íƒ­ êµ¬ì¡° ìƒì„±
        self.setup_main_tabs()
        
        # [Critical] ë°ì´í„° ë¡œë”© ìŠ¤ë ˆë“œ ì‹œì‘
        threading.Thread(target=self.load_data, daemon=True).start()

    # ==========================================================
    # [UI Layout] 3-Tab Structure
    # ==========================================================
    def setup_main_tabs(self):
        # ìŠ¤íƒ€ì¼ ì„¤ì •
        style = ttk.Style()
        style.configure("TNotebook.Tab", font=("ë§‘ì€ ê³ ë”•", 11, "bold"), padding=[10, 5])
        
        self.notebook = ttk.Notebook(self.root)
        self.notebook.pack(fill="both", expand=True, padx=5, pady=5)

        # --- Tab 1: Dashboard (ì¢…í•© ìƒí™©ì‹¤) ---
        self.tab_dashboard = tk.Frame(self.notebook)
        self.notebook.add(self.tab_dashboard, text="  ğŸ“Š ëŒ€ì‹œë³´ë“œ (Monitor)  ")
        self.setup_tab1_dashboard()

        # --- Tab 2: Concept Fortress (ì‹¤ì „ê°œë… ê´€ë¦¬) ---
        self.tab_concepts = tk.Frame(self.notebook)
        self.notebook.add(self.tab_concepts, text="  ğŸ›¡ï¸ ì‹¤ì „ê°œë… ê´€ë¦¬ (Concept DB)  ")
        self.setup_tab2_concepts()

        # --- Tab 3: Problem CMS (ê¸°ì¶œë¬¸ì œ ê´€ë¦¬) ---
        self.tab_problems = tk.Frame(self.notebook)
        self.notebook.add(self.tab_problems, text="  ğŸ“ ê¸°ì¶œë¬¸ì œ CMS (Problem Manager)  ")
        self.setup_tab3_problems()

    # ----------------------------------------------------------
    # Tab 1: Dashboard Implementation
    # ----------------------------------------------------------
    def setup_tab1_dashboard(self):
        paned = tk.PanedWindow(self.tab_dashboard, orient=tk.HORIZONTAL)
        paned.pack(fill="both", expand=True, padx=10, pady=10)
        
        frame_left = tk.Frame(paned)
        frame_right = tk.Frame(paned)
        paned.add(frame_left)
        paned.add(frame_right)

        # Title & Status
        tk.Label(frame_left, text="ğŸš€ MathBot System Log", font=("ë§‘ì€ ê³ ë”•", 16, "bold")).pack(pady=10)
        
        self.btn_run = tk.Button(frame_left, text="ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...", command=self.start_process, 
                                 bg="#cccccc", fg="black", font=("ë§‘ì€ ê³ ë”•", 12, "bold"), height=2, state="disabled")
        self.btn_run.pack(fill="x", padx=20, pady=10)
        
        self.lbl_status = tk.Label(frame_left, text="ëŒ€ê¸° ì¤‘", font=("ë§‘ì€ ê³ ë”•", 11), fg="blue")
        self.lbl_status.pack(pady=5)


        # System Log
        frame_log = tk.LabelFrame(frame_left, text="ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ ë¡œê·¸")
        frame_log.pack(fill="both", expand=True, padx=5, pady=5)
        self.log_area = scrolledtext.ScrolledText(frame_log, state='disabled', font=("Consolas", 10))
        self.log_area.pack(fill="both", expand=True, padx=5, pady=5)

        # History
        frame_hist = tk.LabelFrame(frame_right, text="ì‘ì—… íˆìŠ¤í† ë¦¬ (ë”ë¸”í´ë¦­ ì´ë™)")
        frame_hist.pack(fill="both", expand=True, padx=5, pady=5)
        self.list_hist = tk.Listbox(frame_hist, font=("ë§‘ì€ ê³ ë”•", 11), bg="#f9f9f9")
        self.list_hist.pack(side="left", fill="both", expand=True, padx=5, pady=5)
        sb_hist = tk.Scrollbar(frame_hist, command=self.list_hist.yview)
        sb_hist.pack(side="right", fill="y")
        self.list_hist.config(yscrollcommand=sb_hist.set)
        self.list_hist.bind("<Double-Button-1>", self.on_history_double_click)

    # ----------------------------------------------------------
    # Tab 2: Concept Fortress Implementation
    # ----------------------------------------------------------
    def setup_tab2_concepts(self):
        paned = tk.PanedWindow(self.tab_concepts, orient=tk.HORIZONTAL)
        paned.pack(fill="both", expand=True, padx=5, pady=5)
        
        # Left: List
        frame_list = tk.LabelFrame(paned, text="ì‹¤ì „ê°œë… DB ëª©ë¡ (ë‹¤ì¤‘ì„ íƒ: Ctrl/Shift)")
        paned.add(frame_list, width=600)
        
        # Treeview Setting
        columns = ("title", "status")
        self.tree_concepts = ttk.Treeview(frame_list, columns=columns, show="headings", selectmode="extended")
        self.tree_concepts.heading("title", text="ê°œë… ì œëª©", anchor="w")
        self.tree_concepts.heading("status", text="ìƒíƒœ", anchor="center")
        self.tree_concepts.column("title", width=400)
        self.tree_concepts.column("status", width=80, anchor="center")
        
        # Tags for Coloring (V24 Style)
        self.tree_concepts.tag_configure("evenrow", background="white")
        self.tree_concepts.tag_configure("oddrow", background="#f0f0f5")
        self.tree_concepts.tag_configure("suspect", background="#ffebee", foreground="red")
        self.tree_concepts.tag_configure("group_a", background="#e3f2fd")
        self.tree_concepts.tag_configure("group_b", background="#ffffff")
        
        sb_tree = tk.Scrollbar(frame_list, command=self.tree_concepts.yview)
        self.tree_concepts.configure(yscrollcommand=sb_tree.set)
        self.tree_concepts.pack(side="left", fill="both", expand=True)
        sb_tree.pack(side="right", fill="y")
        
        self.tree_concepts.bind("<<TreeviewSelect>>", self.on_concept_select)

        # Toolbar
        frame_toolbar = tk.Frame(frame_list)
        frame_toolbar.pack(side="bottom", fill="x", pady=5)
        
        # Row 1
        frame_row1 = tk.Frame(frame_toolbar)
        frame_row1.pack(fill="x", pady=2)
        tk.Button(frame_row1, text="ğŸ”— ë³‘í•© (Merge)", command=self.on_merge_btn_click, bg="#FF9800", fg="white").pack(side="left", fill="x", expand=True, padx=2)
        tk.Button(frame_row1, text="ğŸ§² ìœ ì‚¬ì •ë ¬ (Sort)", command=self.on_sort_similarity, bg="#2196F3", fg="white").pack(side="left", fill="x", expand=True, padx=2)
        tk.Button(frame_row1, text="ğŸ”„ ìƒˆë¡œê³ ì¹¨", command=self.update_concept_list).pack(side="right", padx=2)
        
        # Row 2
        frame_row2 = tk.Frame(frame_toolbar)
        frame_row2.pack(fill="x", pady=2)
        tk.Button(frame_row2, text="ğŸ§¹ íƒœê·¸ì œê±°", command=self.on_remove_tag, bg="#9E9E9E", fg="white").pack(side="left", fill="x", expand=True, padx=2)
        tk.Button(frame_row2, text="ğŸ³ï¸ ë¬´ì‹œí•˜ê¸° (Whitelist)", command=self.on_whitelist, bg="#607D8B", fg="white").pack(side="left", fill="x", expand=True, padx=2)

        # Right: Detail Editor
        frame_detail = tk.LabelFrame(paned, text="ìƒì„¸ ë‚´ìš© ì—ë””í„°")
        paned.add(frame_detail)
        
        frame_edit_tools = tk.Frame(frame_detail)
        frame_edit_tools.pack(fill="x", padx=5, pady=5)
        tk.Button(frame_edit_tools, text="ğŸ’¾ ìˆ˜ì • ì €ì¥", command=self.on_save_concept_edit, bg="#4CAF50", fg="white").pack(side="left")
        tk.Button(frame_edit_tools, text="ğŸ—‘ï¸ ì‚­ì œ", command=self.on_delete_concept, bg="#f44336", fg="white").pack(side="right")
        
        self.txt_concept_content = scrolledtext.ScrolledText(frame_detail, font=("ë§‘ì€ ê³ ë”•", 10))
        self.txt_concept_content.pack(fill="both", expand=True, padx=5, pady=5)

    # ----------------------------------------------------------
    # Tab 3: Problem CMS Implementation (New Feature)
    # ----------------------------------------------------------
    def setup_tab3_problems(self):
        # 3-Panel Layout: List | Editor | Linker
        paned = tk.PanedWindow(self.tab_problems, orient=tk.HORIZONTAL)
        paned.pack(fill="both", expand=True, padx=5, pady=5)
        
        # --- Left: Problem List ---
        frame_left = tk.LabelFrame(paned, text="ê¸°ì¶œë¬¸ì œ ëª©ë¡ (Local Repo)")
        paned.add(frame_left, width=350)
        
        self.entry_prob_search = tk.Entry(frame_left)
        self.entry_prob_search.pack(fill="x", padx=5, pady=5)
        self.entry_prob_search.bind("<Return>", self.filter_problem_list)
        tk.Button(frame_left, text="ğŸ” ê²€ìƒ‰", command=self.filter_problem_list).pack(fill="x", padx=5)
        
        self.list_problems = tk.Listbox(frame_left, font=("ë§‘ì€ ê³ ë”•", 10), bg="#fafafa")
        sb_prob = tk.Scrollbar(frame_left, command=self.list_problems.yview)
        self.list_problems.config(yscrollcommand=sb_prob.set)
        self.list_problems.pack(side="left", fill="both", expand=True)
        sb_prob.pack(side="right", fill="y")
        self.list_problems.bind("<<ListboxSelect>>", self.on_problem_select)

        # --- Center: Editor (Image + Metadata + Text) ---
        frame_center = tk.LabelFrame(paned, text="ë¬¸ì œ ì—ë””í„° (Quick Fix)")
        paned.add(frame_center, width=600)
        
        # 1. Image Preview Area
        self.frame_preview = tk.Frame(frame_center, height=250, bg="black")
        self.frame_preview.pack(fill="x", padx=5, pady=5)
        self.lbl_image_preview = tk.Label(self.frame_preview, text="ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°", fg="white", bg="black")
        self.lbl_image_preview.pack(fill="both", expand=True)
        
        # 2. Metadata Editor
        frame_meta = tk.LabelFrame(frame_center, text="ë©”íƒ€ë°ì´í„° ìˆ˜ì •")
        frame_meta.pack(fill="x", padx=5, pady=5)
        
        tk.Label(frame_meta, text="ë‚œì´ë„:").grid(row=0, column=0, padx=2)
        self.combo_diff = ttk.Combobox(frame_meta, values=["ìµœìƒ", "ìƒ", "ì¤‘", "í•˜"], width=5)
        self.combo_diff.grid(row=0, column=1, padx=2)
        
        tk.Label(frame_meta, text="ì¶œì²˜:").grid(row=0, column=2, padx=2)
        self.entry_source = tk.Entry(frame_meta, width=15)
        self.entry_source.grid(row=0, column=3, padx=2)
        
        tk.Label(frame_meta, text="ì—°ë„:").grid(row=0, column=4, padx=2)
        self.entry_year = tk.Entry(frame_meta, width=6)
        self.entry_year.grid(row=0, column=5, padx=2)
        
        tk.Button(frame_meta, text="ğŸ’¾ ë©”íƒ€ ì €ì¥", command=self.save_problem_metadata, bg="#FFC107").grid(row=0, column=6, padx=10)

        # 3. Text Editor
        notebook_editor = ttk.Notebook(frame_center)
        notebook_editor.pack(fill="both", expand=True, padx=5, pady=5)
        
        self.txt_prob_text = scrolledtext.ScrolledText(notebook_editor, height=10)
        notebook_editor.add(self.txt_prob_text, text="ë¬¸ì œ ë³¸ë¬¸ (Problem)")
        
        self.txt_sol_text = scrolledtext.ScrolledText(notebook_editor, height=10)
        notebook_editor.add(self.txt_sol_text, text="AI í•´ì„¤ (Solution)")
        
        tk.Button(frame_center, text="ğŸ’¾ í…ìŠ¤íŠ¸(ë³¸ë¬¸/í•´ì„¤) ë…¸ì…˜ ë°˜ì˜", command=self.save_problem_text, bg="#4CAF50", fg="white").pack(fill="x", padx=5, pady=5)

        # --- Right: Linker ---
        frame_right = tk.LabelFrame(paned, text="ğŸ”— ì‹¤ì „ê°œë… ë§ì»¤ (The Linker)")
        paned.add(frame_right, width=300)
        
        self.list_linked_concepts = tk.Listbox(frame_right, bg="#e0f7fa")
        self.list_linked_concepts.pack(fill="both", expand=True, padx=5, pady=5)
        
        tk.Button(frame_right, text="â• ê°œë… ì—°ê²° (Connect)", command=self.open_linker_dialog, bg="#2196F3", fg="white").pack(fill="x", padx=5, pady=2)
        tk.Button(frame_right, text="â– ì—°ê²° í•´ì œ (Disconnect)", command=self.disconnect_concept, bg="#f44336", fg="white").pack(fill="x", padx=5, pady=2)
        
        tk.Label(frame_right, text="-"*30).pack(pady=5)
        tk.Button(frame_right, text="ğŸ—‘ï¸ [ìœ„í—˜] ë¬¸ì œ ì™„ì „ ì‚­ì œ", command=self.delete_problem_complete, bg="#000000", fg="red").pack(fill="x", padx=5, pady=20)

    # ==========================================================
    # [Logic] Helper Functions & Shared Logs
    # ==========================================================
    def log(self, msg):
        try:
            self.log_area.config(state='normal')
            
            # [Memory Guard] ë¡œê·¸ê°€ ë„ˆë¬´ ê¸¸ì–´ì§€ë©´ ì•ë¶€ë¶„ì„ ì˜ë¼ë‚´ì–´ ë©”ëª¨ë¦¬ í­ë°œ ë°©ì§€
            # í˜„ì¬ ë¼ì¸ ìˆ˜ê°€ 3000ì¤„ì„ ë„˜ì–´ê°€ë©´, ê°€ì¥ ì˜¤ë˜ëœ 500ì¤„ì„ ì‚­ì œí•¨
            if float(self.log_area.index('end-1c')) > 3000:
                self.log_area.delete('1.0', '500.0')
                
            self.log_area.insert(tk.END, f"[{datetime.now().strftime('%H:%M:%S')}] {msg}\n")
            self.log_area.see(tk.END)
            self.log_area.config(state='disabled')
        except: pass
    
    def add_history(self, msg, url):
        self.history_data.append(url)
        self.list_hist.insert(tk.END, msg)
        self.list_hist.see(tk.END)

    def on_history_double_click(self, event):
        selection = self.list_hist.curselection()
        if not selection: return
        idx = selection[0]
        if idx < len(self.history_data):
            webbrowser.open(self.history_data[idx])

    def move_to_dir(self, src_path, dest_dir, filename):
        try:
            if not os.path.exists(dest_dir): os.makedirs(dest_dir)
            shutil.move(src_path, os.path.join(dest_dir, filename))
        except Exception as e:
            self.log(f"âš  íŒŒì¼ ì´ë™ ì‹¤íŒ¨ ({filename}): {e}")

    def git_push_updates(self, repo_path):
        """[V24 Logic] Git Sync Robustness (With Timeout Safety)"""
        try:
            # íƒ€ì„ì•„ì›ƒ 60ì´ˆ ì„¤ì •: 1ë¶„ ì•ˆì— ë°˜ì‘ ì—†ìœ¼ë©´ ê°•ì œ ì¢…ë£Œí•˜ê³  ë‹¤ìŒ ì‘ì—…ìœ¼ë¡œ ë„˜ì–´ê°
            # ì´ë ‡ê²Œ í•´ì•¼ í”„ë¡œê·¸ë¨ì´ ë©ˆì¶”ì§€ ì•ŠìŒ.
            
            # 1. Pull (Rebase)
            subprocess.run(["git", "pull", "--rebase"], cwd=repo_path, check=False, 
                           stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, timeout=60)
            
            # 2. Add
            subprocess.run(["git", "add", "."], cwd=repo_path, check=True, 
                           stdout=subprocess.DEVNULL, stderr=subprocess.PIPE, timeout=60)
            
            # 3. Commit
            subprocess.run(["git", "commit", "-m", "Auto Upload by MathBot"], cwd=repo_path, check=False, 
                           stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, timeout=60)
            
            # 4. Push (ê°€ì¥ ìœ„í—˜í•œ êµ¬ê°„)
            subprocess.run(["git", "push"], cwd=repo_path, check=True, capture_output=True, text=True, timeout=90)
            
            self.root.after(0, lambda: self.log(f"ğŸš€ [Git] ì—…ë¡œë“œ ì™„ë£Œ: {os.path.basename(repo_path)}"))
            
        except subprocess.TimeoutExpired:
            self.root.after(0, lambda: self.log(f"âŒ [Git Error] ì‹œê°„ ì´ˆê³¼! (Timeout). ë„¤íŠ¸ì›Œí¬ë¥¼ í™•ì¸í•˜ì„¸ìš”."))
        except subprocess.CalledProcessError as e:
            error_msg = e.stderr.strip() if e.stderr else str(e)
            self.root.after(0, lambda: self.log(f"âŒ [Git Error] Push ì‹¤íŒ¨: {error_msg}"))
        except Exception as e:
            self.root.after(0, lambda: self.log(f"âŒ [Git Error] ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}"))

    def normalize_text(self, text):
        split_patterns = [r'##\s*í’€ì´', r'##\s*ì •ë‹µ', r'##\s*í•´ì„¤', r'\*\*í’€ì´\*\*', r'Sol\)', r'Solution', r'ì •ë‹µ']
        for pat in split_patterns:
            parts = re.split(pat, text, flags=re.IGNORECASE)
            if len(parts) > 1: text = parts[0]; break
        text = re.sub(r'\\[a-zA-Z]+', '', text)
        garbage = ['$$', '$', '{', '}', ' ', '*', '#', '-', '[', ']', '(', ')', '`', '|', '&', '\\', 'hline', 'clines']
        for g in garbage: text = text.replace(g, '')
        return text

    def extract_numbers(self, text):
        return set(re.findall(r'\d+(?:\.\d+)?', text))

    def load_data(self):
        self.log("ğŸ“¡ ì‹œìŠ¤í…œ ì‹œë™ ì¤‘... (V27 Full Mode)")
        
        # 1. Notion Sync
        try:
            self.log("   (1/3) Notion DB ë™ê¸°í™”...")
            total = notion_api.sync_db_to_memory(lambda x: None)
            self.log(f"   âœ… Notion ë°ì´í„° í™•ë³´: {total}ê°œ")
        except Exception as e:
            self.log(f"   âŒ Notion Sync ì‹¤íŒ¨: {e}")
            
        # 2. Local MD Files
        self.log("   (2/3) ë¡œì»¬ ë¬¸ì œ ë°ì´í„° ìŠ¤ìº”...")
        self.md_files = []
        if os.path.exists(config.MD_DIR_PATH):
            files = [f for f in os.listdir(config.MD_DIR_PATH) if f.lower().endswith(".md")]
            for f in files:
                try:
                    with open(os.path.join(config.MD_DIR_PATH, f), "r", encoding="utf-8") as file:
                        content = file.read()
                        self.md_files.append(f)
                        self.md_contents.append(content)
                        self.search_corpus.append(self.normalize_text(content))
                        self.md_numbers.append(self.extract_numbers(content))
                except: pass
            self.refresh_problem_list()
        
        # Build Vectorizer
        self.log(f"   âš™ï¸ ê²€ìƒ‰ ì—”ì§„ ë¹Œë“œ ì¤‘ ({len(self.md_files)}ê°œ)...")
        if self.search_corpus:
            self.vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(3, 5))
            self.tfidf_matrix = self.vectorizer.fit_transform(self.search_corpus)
        else:
            self.vectorizer = None

        # 3. Concept Map
        self.log("   (3/3) ì‹¤ì „ê°œë… DB ë¡œë“œ...")
        try:
            self.concept_map = concept_sync.get_existing_map() or {}
            self.update_concept_list()
        except: pass
        
        self.log("âœ… ëª¨ë“  ì¤€ë¹„ ì™„ë£Œ. ëŒ€ì‹œë³´ë“œê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        self.btn_run.config(state="normal", bg="#4CAF50", fg="white", text="â–¶ ìë™í™” ì‹œì‘")
        self.lbl_status.config(text="ì¤€ë¹„ ì™„ë£Œ", fg="green")
        
        # [í”Œë˜ê·¸ ì´ˆê¸°í™”]
        self.is_running = False 

    # â–¼â–¼â–¼â–¼â–¼ [ìˆ˜ì •ë¨: ì‹œì‘/ì¤‘ì§€ í† ê¸€ ë¡œì§ ì ìš©] â–¼â–¼â–¼â–¼â–¼
    def start_process(self):
        if not self.is_running:
            # ì‹œì‘ ë¡œì§
            self.is_running = True
            self.btn_run.config(text="â¹ ìë™í™” ì¤‘ì§€ (í´ë¦­)", bg="#f44336") # ë¹¨ê°„ìƒ‰ìœ¼ë¡œ ë³€ê²½
            self.lbl_status.config(text="ğŸ”¥ ìë™í™” ë£¨í”„ ê°€ë™ ì¤‘... (24h)", fg="blue")
            threading.Thread(target=self.process_logic, daemon=True).start()
        else:
            # ì¤‘ì§€ ë¡œì§
            self.is_running = False
            self.btn_run.config(state="disabled", text="ì¤‘ì§€ ìš”ì²­ ì¤‘...")
            self.log("ğŸ›‘ ì‚¬ìš©ì ìš”ì²­ì— ì˜í•´ ë£¨í”„ë¥¼ ì •ì§€í•©ë‹ˆë‹¤. (í˜„ì¬ ì‘ì—… ì™„ë£Œ í›„ ì¢…ë£Œ)")
    # â–²â–²â–²â–²â–² [ì—¬ê¸°ê¹Œì§€ êµì²´] â–²â–²â–²â–²â–²
    
    # ==========================================================
    # [Logic] Tab 2: Concept Manager Handlers
    # ==========================================================
    def update_concept_list(self):
        for item in self.tree_concepts.get_children():
            self.tree_concepts.delete(item)
        concepts = concept_manager.load_concepts()
        sorted_concepts = sorted(concepts, key=lambda x: x['title'])
        for i, c in enumerate(sorted_concepts):
            title = c['title']
            tags = ()
            if "(ì¤‘ë³µì˜ì‹¬)" in title:
                tags = ("suspect",)
                stat = "âš ï¸ í™•ì¸í•„ìš”"
            else:
                tags = ("evenrow",) if i % 2 == 0 else ("oddrow",)
                stat = "ì •ìƒ"
            self.tree_concepts.insert("", "end", values=(title, stat), tags=tags)

    def on_concept_select(self, event):
        sel = self.tree_concepts.selection()
        if not sel: return
        if len(sel) > 1:
            self.txt_concept_content.delete("1.0", tk.END)
            self.txt_concept_content.insert(tk.END, f"âœ… {len(sel)}ê°œ í•­ëª© ì„ íƒë¨.\n[ë³‘í•©] ë˜ëŠ” [ì‚­ì œ]ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”.")
            return
        vals = self.tree_concepts.item(sel[0])['values']
        if not vals: return
        title = vals[0]
        concepts = concept_manager.load_concepts()
        target = next((i for i in concepts if i['title'] == title), None)
        self.txt_concept_content.delete("1.0", tk.END)
        if target: self.txt_concept_content.insert(tk.END, target.get('content', ''))

    def get_selected_concepts(self):
        return [self.tree_concepts.item(i)['values'][0] for i in self.tree_concepts.selection()]

    def on_sort_similarity(self):
        """[V24 Logic] ìœ ì‚¬ë„ ì •ë ¬ + ìƒ‰ìƒ êµì°¨ ì™„ë²½ ë³µêµ¬"""
        self.log("ğŸ§² ìœ ì‚¬ë„ ë¶„ì„ ë° ì •ë ¬ ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŒ)")
        self.root.update() 
        
        # ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ ë°›ì•„ì˜´
        sorted_list = concept_manager.get_similarity_clusters()
        
        # Treeview ë¹„ìš°ê¸°
        for item in self.tree_concepts.get_children():
            self.tree_concepts.delete(item)
            
        # ê·¸ë£¹ë³„ ìƒ‰ìƒ ì¹ í•˜ê¸° ë¡œì§ (V24 ê·¸ëŒ€ë¡œ ì ìš©)
        current_bg_tag = "group_a" # ì‹œì‘ ìƒ‰ìƒ
        prev_title = ""
        
        for title in sorted_list:
            status_text = "ì •ìƒ"
            row_tag = ()
            
            # 1. ì¤‘ë³µì˜ì‹¬ íƒœê·¸ ìš°ì„  ì ìš©
            if "(ì¤‘ë³µì˜ì‹¬)" in title:
                row_tag = ("suspect",)
                status_text = "âš ï¸ í™•ì¸í•„ìš”"
            else:
                # 2. ê·¸ë£¹ ìƒ‰ìƒ ë¡œì§
                if prev_title:
                    norm_curr = concept_manager.normalize_fingerprint(title)
                    norm_prev = concept_manager.normalize_fingerprint(prev_title)
                    sim = difflib.SequenceMatcher(None, norm_curr, norm_prev).ratio()
                    
                    # ìœ ì‚¬ë„ê°€ ëš ë–¨ì–´ì§€ë©´(0.4 ë¯¸ë§Œ) ë‹¤ë¥¸ ê·¸ë£¹ìœ¼ë¡œ ê°„ì£¼ -> ë°°ê²½ìƒ‰ ë³€ê²½
                    if sim < 0.4:
                        current_bg_tag = "group_b" if current_bg_tag == "group_a" else "group_a"
                
                row_tag = (current_bg_tag,)
                
            self.tree_concepts.insert("", "end", values=(title, status_text), tags=row_tag)
            prev_title = title # ë‹¤ìŒ ë¹„êµë¥¼ ìœ„í•´ ì €ì¥
        
        self.log(f"âœ… ì •ë ¬ ì™„ë£Œ ({len(sorted_list)}ê°œ)")
        messagebox.showinfo("ì •ë ¬ ì™„ë£Œ", "ìœ ì‚¬í•œ í•­ëª©ë¼ë¦¬ ë°°ê²½ìƒ‰ì„ ë¬¶ì–´ì„œ ì •ë ¬í–ˆìŠµë‹ˆë‹¤.\nëª©ë¡ì„ í™•ì¸í•˜ì„¸ìš”.")

    def on_merge_btn_click(self):
        titles = self.get_selected_concepts()
        if len(titles) < 2: return messagebox.showwarning("ê²½ê³ ", "2ê°œ ì´ìƒ ì„ íƒí•˜ì„¸ìš”.")
        
        clean = re.sub(r'^\(ì¤‘ë³µì˜ì‹¬\)\s*\[\d+%\]\s*', '', titles[0])
        master = simpledialog.askstring("ë³‘í•©", f"ëŒ€í‘œ ì œëª©(Master) ì…ë ¥:\ní›„ë³´: {titles[0]}", initialvalue=clean)
        if not master: return

        if master not in titles:
            if not messagebox.askyesno("í™•ì¸", f"'{master}'ëŠ” ëª©ë¡ì— ì—†ìŠµë‹ˆë‹¤. '{titles[0]}'ì„ ì´ ì´ë¦„ìœ¼ë¡œ ë³€ê²½í•˜ë©° ë³‘í•©í•©ë‹ˆê¹Œ?"): return
            if master != titles[0]:
                self.log(f"â„¹ï¸ ì‹œìŠ¤í…œìƒ '{titles[0]}' ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©ë©ë‹ˆë‹¤. ì™„ë£Œ í›„ ì´ë¦„ì„ ìˆ˜ì •í•˜ì„¸ìš”.")
                master = titles[0]

        slaves = [t for t in titles if t != master]
        if concept_manager.merge_concepts_manual(master, slaves):
            self.log("ğŸ“¡ ë…¸ì…˜ ë™ê¸°í™” (ë³‘í•©)...")
            for s in slaves:
                k = s.replace(" ", "")
                if k in self.concept_map:
                    concept_sync.delete_concept_page(self.concept_map[k])
                    del self.concept_map[k]
            
            concepts = concept_manager.load_concepts()
            m_item = next((i for i in concepts if i['title'] == master), None)
            if m_item:
                k = master.replace(" ", "")
                if k in self.concept_map:
                    concept_sync.update_concept_page(self.concept_map[k], master, m_item.get('content', ""))
            
            self.update_concept_list()
            self.log("âœ… ë³‘í•© ì™„ë£Œ")

    def on_remove_tag(self):
        titles = self.get_selected_concepts()
        cnt = 0
        for t in titles:
            if "(ì¤‘ë³µì˜ì‹¬)" not in t: continue
            res = concept_manager.remove_suspect_tag(t)
            if res == True:
                old_k = t.replace(" ", "")
                if old_k in self.concept_map:
                    concept_sync.delete_concept_page(self.concept_map[old_k])
                    del self.concept_map[old_k]
                cnt += 1
        if cnt: self.update_concept_list(); self.log(f"ğŸ§¹ {cnt}ê°œ íƒœê·¸ ì œê±°")

    def on_whitelist(self):
        titles = self.get_selected_concepts()
        if len(titles) < 2: return
        cnt = 0
        for i in range(len(titles)):
            for j in range(i+1, len(titles)):
                concept_manager.add_to_whitelist(titles[i], titles[j])
                cnt += 1
        self.log(f"ğŸ³ï¸ {cnt}ìŒ í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ë“±ë¡")

    def on_save_concept_edit(self):
        titles = self.get_selected_concepts()
        if len(titles) != 1: return
        title = titles[0]
        content = self.txt_concept_content.get("1.0", tk.END).strip()
        if messagebox.askyesno("ì €ì¥", f"'{title}' ìˆ˜ì • ì €ì¥?"):
            if concept_manager.manual_update_concept(title, content):
                k = title.replace(" ", "")
                if k in self.concept_map:
                    concept_sync.update_concept_page(self.concept_map[k], title, content)
                self.log(f"ğŸ’¾ ìˆ˜ì • ì™„ë£Œ: {title}")

    def on_delete_concept(self):
        titles = self.get_selected_concepts()
        if not titles: return
        if messagebox.askyesno("ì‚­ì œ", f"{len(titles)}ê°œ ì˜êµ¬ ì‚­ì œ?"):
            for t in titles:
                k = t.replace(" ", "")
                if k in self.concept_map:
                    concept_sync.delete_concept_page(self.concept_map[k])
                    del self.concept_map[k]
                concept_manager.delete_concept(t)
            self.update_concept_list()
            self.txt_concept_content.delete("1.0", tk.END)
            self.log("ğŸ—‘ï¸ ì‚­ì œ ì™„ë£Œ")

    # ==========================================================
    # [Logic] Tab 3: Problem CMS Handlers
    # ==========================================================
    def refresh_problem_list(self):
        self.list_problems.delete(0, tk.END)
        for f in sorted(self.md_files):
            self.list_problems.insert(tk.END, f)
            
    def filter_problem_list(self, event=None):
        query = self.entry_prob_search.get().lower().strip()
        self.list_problems.delete(0, tk.END)
        for f in self.md_files:
            if query in f.lower():
                self.list_problems.insert(tk.END, f)

    def find_local_image_path(self, filename_base):
        exts = ['.jpg', '.png', '.jpeg']
        for repo in config.LOCAL_REPO_PATHS:
            for ext in exts:
                path = os.path.join(repo, filename_base + ext)
                if os.path.exists(path): return path
        for ext in exts:
            path = os.path.join(COMPLETED_DIR, filename_base + ext)
            if os.path.exists(path): return path
        return None

    def on_problem_select(self, event):
        sel = self.list_problems.curselection()
        if not sel: return
        filename = self.list_problems.get(sel[0])
        self.current_problem_file = filename
        
        # 1. Load MD Content
        md_path = os.path.join(config.MD_DIR_PATH, filename)
        content = ""
        try:
            with open(md_path, "r", encoding="utf-8") as f: content = f.read()
        except: content = "íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        prob_text = ""
        sol_text = ""
        if "## ë¬¸ì œ" in content:
            parts = content.split("## ë¬¸ì œ")
            if len(parts) > 1:
                sub = parts[1].split("## í•´ì„¤")
                prob_text = sub[0].strip()
                if len(sub) > 1: sol_text = sub[1].strip()
        
        self.txt_prob_text.delete("1.0", tk.END)
        self.txt_prob_text.insert(tk.END, prob_text)
        self.txt_sol_text.delete("1.0", tk.END)
        self.txt_sol_text.insert(tk.END, sol_text)
        
        # 2. Load Image Preview
        base_name = os.path.splitext(filename)[0]
        img_path = self.find_local_image_path(base_name)
        
        if img_path:
            try:
                pil_img = Image.open(img_path)
                pil_img.thumbnail((500, 230))
                self.current_preview_image = ImageTk.PhotoImage(pil_img)
                self.lbl_image_preview.config(image=self.current_preview_image, text="")
            except:
                self.lbl_image_preview.config(image="", text="ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨")
        else:
            self.lbl_image_preview.config(image="", text="ì´ë¯¸ì§€ ì—†ìŒ")

        # 3. Find Notion Page
        page_id, _ = notion_api.find_page_id(filename)
        self.current_page_id = page_id
        
        if page_id:
            self.lbl_status.config(text=f"Connected: {page_id}", fg="green")
            self.list_linked_concepts.delete(0, tk.END)
            self.list_linked_concepts.insert(tk.END, "-> 'ê°œë… ì—°ê²°' ë²„íŠ¼ì„ ëˆŒëŸ¬ ì¶”ê°€í•˜ì„¸ìš”.")
        else:
            self.lbl_status.config(text="Notion Not Found", fg="red")

    def save_problem_metadata(self):
        if not hasattr(self, 'current_page_id') or not self.current_page_id:
            return messagebox.showerror("ì˜¤ë¥˜", "ë…¸ì…˜ í˜ì´ì§€ì™€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        messagebox.showinfo("ì•Œë¦¼", "í˜„ì¬ API êµ¬ì¡°ìƒ í…ìŠ¤íŠ¸ ì†ì„± ì™¸ ì—…ë°ì´íŠ¸ëŠ” ì œí•œì ì…ë‹ˆë‹¤.")

    def save_problem_text(self):
        if not hasattr(self, 'current_page_id') or not self.current_page_id: return
        messagebox.showinfo("ì•Œë¦¼", "ì•ˆì „í•œ ìˆ˜ì •ì„ ìœ„í•´ 'ì†ì„±(Property)' ì—…ë°ì´íŠ¸ë§Œ ì§€ì›í•©ë‹ˆë‹¤.")

    def open_linker_dialog(self):
        if not hasattr(self, 'current_page_id') or not self.current_page_id:
            return messagebox.showerror("ì˜¤ë¥˜", "ë¬¸ì œë¥¼ ë¨¼ì € ì„ íƒí•˜ì„¸ìš”.")
            
        top = Toplevel(self.root)
        top.title("ì‹¤ì „ê°œë… ì—°ê²° (The Linker)")
        top.geometry("400x500")
        
        lbl = tk.Label(top, text="ì—°ê²°í•  ê°œë…ì„ ê²€ìƒ‰í•˜ì„¸ìš”:")
        lbl.pack(pady=5)
        
        entry = tk.Entry(top)
        entry.pack(fill="x", padx=10)
        
        lst = tk.Listbox(top, selectmode=tk.MULTIPLE)
        lst.pack(fill="both", expand=True, padx=10, pady=5)
        
        all_concepts = sorted(self.concept_map.keys())
        for c in all_concepts: lst.insert(tk.END, c)
        
        def filter_list(e=None):
            q = entry.get().lower()
            lst.delete(0, tk.END)
            for c in all_concepts:
                if q in c.lower(): lst.insert(tk.END, c)
        entry.bind("<KeyRelease>", filter_list)
        
        def do_link():
            sel = lst.curselection()
            if not sel: return
            c_ids = []
            c_titles = []
            for i in sel:
                t = lst.get(i)
                c_titles.append(t)
                c_ids.append(self.concept_map[t])
            res, msg = notion_api.update_page_properties(self.current_page_id, {}, concept_ids=c_ids)
            if res:
                messagebox.showinfo("ì„±ê³µ", f"{len(c_titles)}ê°œ ê°œë…ì´ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")
                top.destroy()
            else:
                messagebox.showerror("ì‹¤íŒ¨", msg)
                
        tk.Button(top, text="ğŸ”— ì„ íƒí•œ ê°œë… ì—°ê²°í•˜ê¸°", command=do_link, bg="#2196F3", fg="white").pack(fill="x", padx=10, pady=10)

    def disconnect_concept(self):
        messagebox.showinfo("ì•Œë¦¼", "ë…¸ì…˜ API ì œí•œìœ¼ë¡œ ì—°ê²° í•´ì œëŠ” ë…¸ì…˜ì—ì„œ ì§ì ‘ í•˜ì‹œëŠ” ê²Œ ì•ˆì „í•©ë‹ˆë‹¤.")

    def delete_problem_complete(self):
        if not hasattr(self, 'current_problem_file') or not self.current_problem_file: return
        fname = self.current_problem_file
        
        if messagebox.askyesno("ê²½ê³ ", f"ì •ë§ '{fname}'ì„ ì™„ì „íˆ ì‚­ì œí•©ë‹ˆê¹Œ?\n(ë¡œì»¬ íŒŒì¼ + ë…¸ì…˜ í˜ì´ì§€ + Gitì—ì„œ ëª¨ë‘ ì‚¬ë¼ì§‘ë‹ˆë‹¤)"):
            if self.current_page_id:
                notion_api.delete_concept_page(self.current_page_id) 
                self.log(f"ğŸ—‘ï¸ ë…¸ì…˜ í˜ì´ì§€ ì‚­ì œ ì™„ë£Œ: {self.current_page_id}")
            
            md_path = os.path.join(config.MD_DIR_PATH, fname)
            if os.path.exists(md_path): os.remove(md_path)
            
            base = os.path.splitext(fname)[0]
            img_path = self.find_local_image_path(base)
            if img_path and os.path.exists(img_path): os.remove(img_path)
            
            self.refresh_problem_list()
            self.txt_prob_text.delete("1.0", tk.END)
            self.lbl_image_preview.config(image="", text="ì‚­ì œë¨")
            self.log(f"ğŸ—‘ï¸ ì™„ì „ ì‚­ì œ ì™„ë£Œ: {fname}")

    # ==========================================================
    # [Logic] AI Judge & Process Loop (V24 Full Restoration)
    # ==========================================================
    def call_ai_judge(self, ocr_text, candidates):
        try:
            candidate_text = ""
            for i, cand in enumerate(candidates):
                candidate_text += f"\n[Candidate {i+1}]: {cand[0]}\nContext: {cand[1][:300]}...\n"

            prompt = f"""
            Role: Mathematical Document Matcher.
            Task: Compare the [OCR Text] with the [Candidates] and identify the exact match.
            STRICTLY CHECK METADATA: Year, Grade, Subject, Month, Authority.
            
            [OCR Text]
            {ocr_text}

            {candidate_text}

            Instructions:
            1. Compare the mathematical structure, numbers, and key terms.
            2. Ignore minor OCR errors.
            3. If Candidate 1 matches, reply "1".
            4. If Candidate 2 matches, reply "2".
            5. If Candidate 3 matches, reply "3".
            6. If NONE match, reply "0".
            
            OUTPUT ONLY THE NUMBER.
            """
            
            response = gemini_api.execute_with_key_rotation(
                gemini_api.analysis_model, 
                [prompt],
                generation_config={"temperature": 0.0, "max_output_tokens": 300},
                request_options=gemini_api.REQUEST_OPTIONS
            )
            
            result = response.text.strip()
            self.log(f"âš–ï¸ [AI Judge] íŒê²°: {result}")
            
            if "1" in result: return 0
            if "2" in result: return 1
            if "3" in result: return 2
            return -1
        except Exception as e:
            self.log(f"âš ï¸ ì‹¬íŒê´€ ì˜¤ë¥˜: {e}")
            return -1

    # ==================================================================================
    # [New Engine] ì´ë¯¸ì§€ í•©ì²´ & ë ˆê±°ì‹œ ì²˜ë¦¬ê¸° (Robustness & Integrity)
    # ==================================================================================
    def merge_images_vertical(self, path1, path2, output_path):
        """
        [Over-engineering] ë‘ ì´ë¯¸ì§€ë¥¼ ì„¸ë¡œë¡œ ì´ì–´ ë¶™ì…ë‹ˆë‹¤.
        í­ì´ ë‹¤ë¥¼ ê²½ìš° í° ìª½ì— ë§ì¶° ë¦¬ì‚¬ì´ì§•í•˜ì—¬ ì •ë ¬ì„ ë§ì¶¥ë‹ˆë‹¤. (ì ˆëŒ€ ì‹¤íŒ¨ ë°©ì§€)
        """
        try:
            img1 = Image.open(path1)
            img2 = Image.open(path2)
            
            # í­ ë§ì¶”ê¸° (Width Matching) - í° ìª½ì— ë¬´ì¡°ê±´ ë§ì¶¤
            w1, h1 = img1.size
            w2, h2 = img2.size
            target_w = max(w1, w2)
            
            # img1 ë¦¬ì‚¬ì´ì§• (í•„ìš”ì‹œ)
            if w1 < target_w:
                ratio = target_w / w1
                new_h1 = int(h1 * ratio)
                img1 = img1.resize((target_w, new_h1), Image.Resampling.LANCZOS)
                h1 = new_h1
            
            # img2 ë¦¬ì‚¬ì´ì§• (í•„ìš”ì‹œ)
            if w2 < target_w:
                ratio = target_w / w2
                new_h2 = int(h2 * ratio)
                img2 = img2.resize((target_w, new_h2), Image.Resampling.LANCZOS)
                h2 = new_h2
                
            # ìº”ë²„ìŠ¤ ìƒì„± (í°ìƒ‰ ë°°ê²½)
            merged_img = Image.new('RGB', (target_w, h1 + h2), (255, 255, 255))
            merged_img.paste(img1, (0, 0))
            merged_img.paste(img2, (0, h1))
            
            merged_img.save(output_path, quality=100)
            self.log(f"ğŸ§© [Merge] ì´ë¯¸ì§€ í•©ì²´ ì„±ê³µ: {os.path.basename(output_path)}")
            return True
        except Exception as e:
            self.log(f"âŒ [Merge Fail] ì´ë¯¸ì§€ ë³‘í•© ì‹¤íŒ¨ (ê°œë³„ ì²˜ë¦¬ë¡œ ì „í™˜í•©ë‹ˆë‹¤): {e}")
            return False

    def process_deep_file_legacy(self, path, img):
        """
        [Core Logic] ê¸°ì¡´ Track Aì˜ ì‹¬ì¸µ ë¶„ì„ ë¡œì§ì„ 100% ì›ë³¸ ê·¸ëŒ€ë¡œ ë³´ì¡´í•œ ì‹¤í–‰ê¸°ì…ë‹ˆë‹¤.
        ì¼ë°˜ íŒŒì¼, ë³‘í•©ëœ íŒŒì¼, íƒ€ì„ì•„ì›ƒëœ íŒŒì¼ ëª¨ë‘ ì´ í•¨ìˆ˜ë¥¼ í†µê³¼í•©ë‹ˆë‹¤.
        """
        try:
            # [Debouncing] íŒŒì¼ ì „ì†¡ ì•ˆì •í™” ëŒ€ê¸° (1ì´ˆ) - í•¨ìˆ˜ ì§„ì… ì‹œì ì—ë„ í•œ ë²ˆ ë” ì²´í¬ (ê³¼ì‰ ë°©ì–´)
            try:
                size_init = os.path.getsize(path)
                time.sleep(1)
                if size_init != os.path.getsize(path): return # ì „ì†¡ ì¤‘ì´ë©´ ì¡°ìš©íˆ ë¦¬í„´ (ë‹¤ìŒ ë£¨í”„ì—ì„œ ì²˜ë¦¬)
            except: return

            # ì ìˆ˜ íŒŒì¼ëª… ì˜¤ì¸ ë°©ì§€ ì •ê·œì‹ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
            if re.search(r'_[1-9]\.[a-zA-Z]+$', img):
                self.move_to_dir(path, ERROR_DIR, img)
                return

            self.root.after(0, lambda f=img: self.log(f"\nğŸ§  [Track A] ì‹¬ì¸µ ë¶„ì„ ì‹œì‘: {f}"))
            
            try:
                # ------------------------------------------------------------------
                # 1. OCR & Hybrid Search Engine (ê¸°ì¡´ ë¡œì§ ì™„ë²½ ë³´ì¡´)
                # ------------------------------------------------------------------
                search_text = gemini_api.get_pure_ocr_text(path)
                
                final_score = 0.0
                best_file = None
                is_new_problem = False
                
                if self.vectorizer and search_text:
                    query_norm = self.normalize_text(search_text)
                    vec = self.vectorizer.transform([query_norm])
                    sims = cosine_similarity(vec, self.tfidf_matrix).flatten()
                    
                    top_indices = sims.argsort()[-3:][::-1]
                    best_idx = top_indices[0]
                    base_score = sims[best_idx]
                    
                    ocr_nums = self.extract_numbers(search_text)
                    md_nums = self.md_numbers[best_idx]
                    
                    num_bonus = 0.0
                    if ocr_nums and md_nums:
                        intersection = ocr_nums.intersection(md_nums)
                        recall = len(intersection) / len(ocr_nums)
                        if recall >= 0.8: num_bonus = 0.3
                        elif recall >= 0.5: num_bonus = 0.15
                    
                    final_score = base_score + num_bonus
                    best_file = self.md_files[best_idx]
                    
                    self.log(f"ğŸ“Š ì ìˆ˜ ë¶„ì„: Base({base_score:.2f}) + NumBonus({num_bonus:.2f}) = {final_score:.2f}")

                    match_decision = "NEW"
                    if final_score >= 0.8: match_decision = "MATCH"
                    elif final_score >= 0.4:
                        self.log(f"âš–ï¸ ì ìˆ˜ ì• ë§¤í•¨ ({final_score:.2f}). AI ì‹¬íŒê´€ ì†Œí™˜!")
                        judge_candidates = []
                        for idx in top_indices:
                            judge_candidates.append((self.md_files[idx], self.md_contents[idx], sims[idx]))
                        winner_idx = self.call_ai_judge(search_text, judge_candidates)
                        if winner_idx != -1:
                            best_file = judge_candidates[winner_idx][0]
                            final_score = 0.99
                            match_decision = "MATCH"
                            self.log(f"ğŸ‰ AI ì‹¬íŒê´€ì´ ë§¤ì¹­ í™•ì •: {best_file}")
                        else:
                            match_decision = "NEW"
                            self.log("âš–ï¸ AI ì‹¬íŒê´€ íŒê²°: ì¼ì¹˜í•˜ëŠ” ë¬¸ì œ ì—†ìŒ -> ì‹ ê·œ ìƒì„±")
                    else: match_decision = "NEW"

                    if match_decision == "MATCH":
                        self.root.after(0, lambda f=best_file, s=final_score: self.log(f"ğŸ” [ë§¤ì¹­] ê¸°ì¡´ ë¬¸ì œ ì—…ë°ì´íŠ¸: {f} (Final: {s:.2f})"))
                        is_new_problem = False
                    else:
                        self.root.after(0, lambda s=final_score: self.log(f"ğŸ†• [ì‹ ê·œ] ìƒì„± ëª¨ë“œ (Final: {s:.2f})"))
                        is_new_problem = True
                else:
                    is_new_problem = True

                # ------------------------------------------------------------------
                # 2. ë¶„ì„ (Forensic Mode)
                # ------------------------------------------------------------------
                self.root.after(0, lambda: self.log("ğŸ§  ìƒì„¸ ë¶„ì„ ì¤‘ (Tag Mode)..."))
                json_data = gemini_api.analyze_image_structure(path)
                
                if not json_data: 
                    self.root.after(0, lambda: self.log("âŒ ë¶„ì„ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨. ERROR ì´ë™."))
                    self.move_to_dir(path, ERROR_DIR, img)
                    return

                try:
                    deep_root_basename = os.path.basename(os.path.normpath(config.DEEP_WATCH_DIR)).strip()
                    parent_folder = os.path.basename(os.path.dirname(path)).strip()
                    folder_tag = "" if parent_folder == deep_root_basename else parent_folder

                    if "db_columns" not in json_data or not isinstance(json_data["db_columns"], dict):
                        json_data["db_columns"] = {}

                    if "tags" not in json_data["db_columns"] or not isinstance(json_data["db_columns"]["tags"], list):
                        json_data["db_columns"]["tags"] = []

                    if folder_tag and folder_tag not in json_data["db_columns"]["tags"]:
                        json_data["db_columns"]["tags"].append(folder_tag)
                        self.log(f"ğŸ·ï¸ [Auto Tag] í´ë”ëª… íƒœê·¸ ì¶”ê°€: {folder_tag}")
                except Exception as e:
                    self.log(f"âš ï¸ [Tag Error] í´ë” íƒœê·¸ ì¶”ê°€ ì‹¤íŒ¨ (ë¬´ì‹œí•˜ê³  ì§„í–‰): {e}")

# ------------------------------------------------------------------
# ------------------------------------------------------------------
                # 3. ê°œë… ID (Concept ID)
                # ------------------------------------------------------------------
                detected_concept_ids = []
                pcs = json_data.get("body_content", {}).get("practical_concepts", [])
                
                # [ì§„ë‹¨ìš© ë«] ë„ëŒ€ì²´ ë­ê°€ ë“¤ì–´ì˜¤ê³  ìˆëŠ”ì§€ í™•ì¸
                self.root.after(0, lambda p=pcs: self.log(f"ğŸ§ª pcs type={type(p)}, sample0={type(p[0]) if isinstance(p, list) and p else None}"))
                
                for c in pcs:
                    if not isinstance(c, dict):
                        self.root.after(0, lambda err=c: self.log(f"âš ï¸ [Loop Error] practical_concepts ìš”ì†Œ ë¶ˆëŸ‰: {type(err)} -> {err}"))
                        continue
                    
                    self.process_single_concept(c) 
                    title_key = c.get('title', '').replace(" ", "")
                    if title_key in self.concept_map:
                        detected_concept_ids.append(self.concept_map[title_key])

                # ------------------------------------------------------------------
                # 4. GitHub & Body Content Packaging

                # ------------------------------------------------------------------
                # 4. GitHub & Body Content Packaging
                # ------------------------------------------------------------------
                repo_idx = 4 
                target_repo_path = config.LOCAL_REPO_PATHS[repo_idx]
                target_repo_name = config.REPO_NAMES[repo_idx]
                
                if is_new_problem: src_name = os.path.splitext(img)[0]
                else: src_name = os.path.splitext(best_file)[0]
                    
                _, ext = os.path.splitext(img)
                safe_name = f"{src_name}{ext}".replace(" ", "_").replace("[", "").replace("]", "").replace("(", "").replace(")", "")
                github_url = f"https://raw.githubusercontent.com/{config.GITHUB_USERNAME}/{target_repo_name}/main/{safe_name}"
                
                if "body_content" in json_data:
                    json_data["body_content"]["image_url"] = github_url
                    if is_new_problem:
                        json_data["body_content"]["problem_text"] = search_text if search_text else "OCR í…ìŠ¤íŠ¸ ì—†ìŒ"
                    else:
                        if "problem_text" in json_data["body_content"]: del json_data["body_content"]["problem_text"]
                    if not json_data["body_content"].get("verbatim_handwriting"):
                        json_data["body_content"]["verbatim_handwriting"] = search_text or "OCR í…ìŠ¤íŠ¸ ì—†ìŒ"

                # ------------------------------------------------------------------
                # 5. Notion Page Creation / Update (ì†ì„± ë° ë³¸ë¬¸ ì—…ë°ì´íŠ¸)
                # ------------------------------------------------------------------
                page_id = None
                if is_new_problem:
                    new_title = os.path.splitext(img)[0]
                    page_id, msg = notion_api.create_new_problem_page(new_title, json_data.get("db_columns", {}), detected_concept_ids)
                    
                    if page_id:
                        notion_api.append_children(page_id, json_data.get("body_content", {}))
                        self.root.after(0, lambda t=new_title: self.log(f"âœ¨ [ìƒì„±] {t}"))
                        
                        # [MD íŒŒì¼ ìƒì„±] - ê¸°ì¡´ì˜ ì•ˆì „ì¥ì¹˜(Overwrite vs New) ë¡œì§ 100% ìœ ì§€
                        md_filename = f"{new_title}.md"
                        md_path = os.path.join(config.MD_DIR_PATH, md_filename)
                        ai_response_text = json_data.get("body_content", {}).get("ai_solution", "í•´ì„¤ ì—†ìŒ")

                        try:
                            current_content = ""
                            if os.path.exists(md_path):
                                with open(md_path, 'r', encoding='utf-8') as f_read: current_content = f_read.read()

                            final_new_content = ""
                            # [Critical Logic] AI_SECTION_MARKER ê¸°ì¤€ìœ¼ë¡œ ë®ì–´ì“°ê¸° ë¡œì§
                            if AI_SECTION_MARKER in current_content:
                                clean_problem_part = current_content.split(AI_SECTION_MARKER)[0]
                                final_new_content = clean_problem_part.rstrip() + AI_SECTION_MARKER + "\n" + ai_response_text
                                self.root.after(0, lambda: self.log(f"â™»ï¸ [ê°±ì‹ ] ê¸°ì¡´ ë¬¸ì œ ìˆ˜ì •ë³¸ì€ ìœ ì§€í•˜ê³ , AI í•´ì„¤ë§Œ êµì²´í–ˆìŠµë‹ˆë‹¤."))
                            elif current_content.strip() != "":
                                final_new_content = current_content.rstrip() + AI_SECTION_MARKER + "\n" + ai_response_text
                                self.root.after(0, lambda: self.log(f"âš ï¸ [êµ¬ì¡°ë³€ê²½] êµ¬ë²„ì „ íŒŒì¼ì— ì•ˆì „ êµ¬ë¶„ì„ ì„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤."))
                            else:
                                problem_base = "# " + str(new_title) + "\n\n## ë¬¸ì œ\n" + str(search_text) + "\n"
                                final_new_content = problem_base.rstrip() + AI_SECTION_MARKER + "\n" + ai_response_text
                                self.root.after(0, lambda: self.log("ğŸ“ [ì‹ ê·œ] ìƒˆ MD íŒŒì¼ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤."))

                            with open(md_path, "w", encoding="utf-8") as f_write: f_write.write(final_new_content)
                        except Exception as e_md:
                            self.root.after(0, lambda: self.log(f"âŒ MD ì‘ì„± ì¤‘ ì˜¤ë¥˜: {e_md}"))
                else:
                    page_id, err = notion_api.find_page_id(best_file)
                    if page_id:
                        notion_api.update_page_properties(page_id, json_data.get("db_columns", {}), concept_ids=detected_concept_ids)
                        notion_api.append_children(page_id, json_data.get("body_content", {}))
                        self.root.after(0, lambda: self.log(f"âœ… Notion ì—…ë°ì´íŠ¸ ì™„ë£Œ"))
                    else:
                        self.root.after(0, lambda: self.log(f"âŒ ë…¸ì…˜ í˜ì´ì§€ ë§¤ì¹­ ê±°ë¶€: {err}"))
                        self.move_to_dir(path, ERROR_DIR, img)
                        return
                
                # ------------------------------------------------------------------
                # 6. ë§ˆë¬´ë¦¬ (íŒŒì¼ ì´ë™ ë° Git Push)
                # ------------------------------------------------------------------
                if page_id:
                    page_url = f"https://www.notion.so/{page_id.replace('-', '')}"
                    self.root.after(0, lambda t=src_name, u=page_url: self.add_history(f"âœ… {t}", u))
                    final_local_path = os.path.join(target_repo_path, safe_name)
                    try: 
                        shutil.move(path, final_local_path)
                        self.git_push_updates(target_repo_path)
                    except Exception as e: self.log(f"âš  ì´ë™/ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
                else:
                    self.move_to_dir(path, ERROR_DIR, img)

            except Exception as e_inner:
                self.root.after(0, lambda: self.log(f"ğŸ’£ ê°œë³„ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e_inner}"))
                self.move_to_dir(path, ERROR_DIR, img)

        except Exception as e_outer:
            self.log(f"ğŸ”¥ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ (Deep Legacy): {e_outer}")
            self.move_to_dir(path, ERROR_DIR, img)

    # â–¼â–¼â–¼â–¼â–¼ [ì—¬ê¸°ì„œë¶€í„° ë³µì‚¬í•´ì„œ ê¸°ì¡´ process_logic í•¨ìˆ˜ë¥¼ ì™„ì „íˆ ë®ì–´ì“°ì„¸ìš”] â–¼â–¼â–¼â–¼â–¼
    # â–¼â–¼â–¼â–¼â–¼ [ì—¬ê¸°ì„œë¶€í„° ë³µì‚¬í•´ì„œ ê¸°ì¡´ process_logic í•¨ìˆ˜ë¥¼ ì™„ì „íˆ ë®ì–´ì“°ì„¸ìš”] â–¼â–¼â–¼â–¼â–¼
    # â–¼â–¼â–¼â–¼â–¼ [ìˆ˜ì •: í•¨ìˆ˜ ë¶„ë¦¬ ì—†ì´ ëª¨ë“  ë¡œì§ì„ ë‚´ë¶€ì— ë•Œë ¤ ë„£ì€ ë¬´ê²°ì„± ë²„ì „] â–¼â–¼â–¼â–¼â–¼
    # â–¼â–¼â–¼â–¼â–¼ [Final Integrity Ver: Merge + Append + Full Logic Inlined] â–¼â–¼â–¼â–¼â–¼
    def process_logic(self):
        """
        [MathBot V28 Hybrid Engine: The Complete Integration (Monolithic)]
        
        [Logic Flow]
        1. Track A (Deep Analysis):
           - Watch '[1]_ì˜¤ë‹µë¶„ì„_Deep'
           - Merge System: Wait 60s for '_1' + '_2' pair. Merge if found.
           - Mode System: Detect '_add'/'_plus' for Append Mode.
           - Execution: Full Forensic Analysis (No Abstraction).
        2. Track B (Fast Collection):
           - Watch '[2]_ìë£Œìˆ˜ì§‘_Fast'
           - Simple OCR + CategoryBrain.
        3. Concept Track:
           - Watch 'ì‹¤ì „ê°œë…'
           - Flexible Extraction.
           
        [Zero-Compromise Principle]
        - No functions used for core logic to ensure visibility.
        - Logic is duplicated for 'Normal Processing' and 'Timeout Processing'.
        - MD generation splits strictly into Append vs Overwrite paths.
        """
        import json # ë¡œì»¬ ì„í¬íŠ¸ (ëˆ„ë½ ë°©ì§€)
        
        # [ì„¤ì •] ë…¸ì…˜ ìºì‹œ ê°±ì‹  ì£¼ê¸° (ì´ˆ ë‹¨ìœ„) - 30ë¶„ë§ˆë‹¤ ê°±ì‹ 
        CACHE_REFRESH_INTERVAL = 1800 
        last_cache_refresh_time = time.time()
        
        # [ì„¤ì •] ë³‘í•© ëŒ€ê¸° ì‹œê°„ (60ì´ˆ)
        MERGE_WAIT_TIMEOUT = 60 
        
        # [Memory] ëŒ€ê¸°ì‹¤: { "íŒŒì¼ëª…_base": {"path": "ê²½ë¡œ", "timestamp": ì‹œê°„} }
        pending_queue = {} 

        self.root.after(0, lambda: self.log("ğŸš€ [System] í•˜ì´ë¸Œë¦¬ë“œ ì—”ì§„ ê°€ë™ (Merge: ON, Append/Overwrite: ON)"))
        self.root.after(0, lambda: self.log(f"ğŸ‘ï¸ [Track A] ê°ì‹œ ì¤‘..."))
        self.root.after(0, lambda: self.log(f"ğŸ‘ï¸ [Track B] ê°ì‹œ ì¤‘..."))

        try:
            while self.is_running:
                processed_any = False
                # ------------------------------------------------------------------
                # [ì•ˆì „ì¥ì¹˜ 1] ê°ì‹œ í´ë” ì¡´ì¬ í™•ì¸ (ë£¨íŠ¸ í´ë”)
                # ------------------------------------------------------------------
                if not os.path.exists(config.WATCH_ROOT_DIR):
                    self.root.after(0, lambda: self.log(f"âŒ ê°ì‹œ ë£¨íŠ¸ í´ë”ê°€ ì‚¬ë¼ì¡ŒìŠµë‹ˆë‹¤: {config.WATCH_ROOT_DIR}"))
                    time.sleep(5)
                    continue

                # ------------------------------------------------------------------
                # [ì•ˆì „ì¥ì¹˜ 2] ë…¸ì…˜ ìºì‹œ ì£¼ê¸°ì  ê°±ì‹ 
                # ------------------------------------------------------------------
                current_time = time.time()
                if current_time - last_cache_refresh_time > CACHE_REFRESH_INTERVAL:
                    self.root.after(0, lambda: self.log("ğŸ”„ [System] ë…¸ì…˜ ë°ì´í„°ë² ì´ìŠ¤ ìºì‹œ ì •ê¸° ê°±ì‹  ì¤‘..."))
                    try:
                        notion_api.sync_db_to_memory(lambda x: None)
                        last_cache_refresh_time = current_time
                        self.root.after(0, lambda: self.log("âœ… [System] ìºì‹œ ê°±ì‹  ì™„ë£Œ."))
                    except Exception as e_sync:
                        self.root.after(0, lambda: self.log(f"âš ï¸ [System] ìºì‹œ ê°±ì‹  ì‹¤íŒ¨ (ë¬´ì‹œ): {e_sync}"))

                # ==================================================================================
                # [Track A] ì˜¤ë‹µ ë¶„ì„ ëª¨ë“œ (Deep Analysis)
                # ==================================================================================
                if os.path.exists(config.DEEP_WATCH_DIR):
                    # âœ… [ì¬ê·€ íƒìƒ‰] í•˜ìœ„ í´ë”ê¹Œì§€ ì´ë¯¸ì§€ ì°¾ê¸°
                    deep_image_paths = []
                    for root, dirs, files in os.walk(config.DEEP_WATCH_DIR):
                        for f in files:
                            if f.lower().endswith(('.jpg', '.png', '.jpeg')):
                                deep_image_paths.append(os.path.join(root, f))

                    if deep_image_paths: processed_any = True

                    # 1. íŒŒì¼ ìŠ¤ìº” ë£¨í”„
                    for path in deep_image_paths:
                        if not self.is_running: break

                        img = os.path.basename(path)
                        root_dir = os.path.dirname(path)

                        # âœ… [íƒœê·¸] Deep í´ë” ë°”ë¡œ ì•„ë˜ í•˜ìœ„í´ë”ëª…ì„ íƒœê·¸ë¡œ ì‚¬ìš©
                        # ì˜ˆ: ...\[1]_ì˜¤ë‹µë¶„ì„_Deep\ë‰´ëŸ°\íŒŒì¼.jpg  -> folder_tag="ë‰´ëŸ°"
                        # Deep ë°”ë¡œ ì•„ë˜ë©´ íƒœê·¸ ì—†ìŒ("")
                        if os.path.normpath(root_dir) == os.path.normpath(config.DEEP_WATCH_DIR):
                            folder_tag = ""
                        else:
                            folder_tag = os.path.basename(root_dir)

                        # [Debouncing] íŒŒì¼ ì „ì†¡ ì•ˆì •í™” ëŒ€ê¸°
                        try:
                            s1 = os.path.getsize(path); time.sleep(0.5)
                            if s1 != os.path.getsize(path): continue
                        except: continue

                        name_base, ext = os.path.splitext(img)


                        # --- [Merge Logic: ëŒ€ê¸°ì—´ ê´€ë¦¬] ---------------------------------
                        
                        # CASE 1: _1.jpg ë°œê²¬ (ëŒ€ê¸°)
                        if name_base.endswith("_1"):
                            core_name = name_base[:-2] # "_1" ì œê±°
                            if core_name in pending_queue: continue # ì´ë¯¸ ëŒ€ê¸° ì¤‘

                            pending_queue[core_name] = {
                                "path": path, "filename": img, "timestamp": time.time()
                            }
                            self.root.after(0, lambda n=img: self.log(f"â³ [Wait] {n} ëŒ€ê¸° ì¤‘... (60ì´ˆ)"))
                            continue # ì²˜ë¦¬ ë³´ë¥˜

                        # CASE 2: _2.jpg ë°œê²¬ (ë³‘í•© ì‹œë„)
                        elif name_base.endswith("_2"):
                            core_name = name_base[:-2]
                            if core_name in pending_queue:
                                info = pending_queue.pop(core_name) # ëŒ€ê¸°ì—´ì—ì„œ êº¼ëƒ„
                                partner_path = info["path"]
                                merged_filename = f"{core_name}_merged{ext}"
                                merged_path = os.path.join(config.DEEP_WATCH_DIR, merged_filename)
                                
                                # self.merge_images_vertical ë©”ì„œë“œ í˜¸ì¶œ (ìƒë‹¨ì— ì •ì˜ë¨)
                                if self.merge_images_vertical(partner_path, path, merged_path):
                                    # ë³‘í•© ì„±ê³µ ì‹œ ì›ë³¸ ë°±ì—… í›„ Continue (ë³‘í•©ëœ íŒŒì¼ì€ ë‹¤ìŒ ë£¨í”„ì—ì„œ ê°ì§€ë¨)
                                    backup_dir = os.path.join(config.DRIVE_WATCH_FOLDER, "_MERGED_ORIGINALS")
                                    if not os.path.exists(backup_dir): os.makedirs(backup_dir)
                                    try:
                                        shutil.move(partner_path, os.path.join(backup_dir, info["filename"]))
                                        shutil.move(path, os.path.join(backup_dir, img))
                                        self.log(f"ğŸ§¹ ì›ë³¸ íŒŒì¼(_1, _2) ë°±ì—… ì™„ë£Œ")
                                    except: pass
                                    continue 
                                else:
                                    pass # ì‹¤íŒ¨ ì‹œ _2ë§Œì´ë¼ë„ ì²˜ë¦¬ ì§„í–‰
                            else:
                                pass # ì§ê¿ ì—†ìœ¼ë©´ _2ë§Œ ì²˜ë¦¬ ì§„í–‰

                        # --- [Core Analysis Logic: ì‹¬ì¸µ ë¶„ì„ ë³¸ì²´ (Inline)] ---------------
                        # CASE 3: ì¼ë°˜ íŒŒì¼ / ë³‘í•©ëœ íŒŒì¼ / ì§ ì—†ëŠ” _2
                        
                        # [NEW] Mode Detection (Append vs Overwrite)
                        # íŒŒì¼ëª…ì— _add, _plus, _append, _added ë“±ì´ ìˆìœ¼ë©´ ì´ì–´ì“°ê¸° ëª¨ë“œ
                        is_append_mode = False
                        if any(trigger in img.lower() for trigger in ["_add", "_plus", "_append", "_added", "ì¶”ê°€"]):
                            is_append_mode = True
                            self.root.after(0, lambda: self.log(f"ğŸ“ [Mode] ì´ì–´ ì“°ê¸°(Append) ëª¨ë“œ ê°ì§€: {img}"))
                        else:
                            self.root.after(0, lambda: self.log(f"ğŸ“ [Mode] ë®ì–´ ì“°ê¸°(Overwrite) ëª¨ë“œ: {img}"))

                        # ì ìˆ˜ íŒŒì¼ëª… ì˜¤ì¸ ë°©ì§€
                        if re.search(r'_[1-9]\.[a-zA-Z]+$', img):
                            self.move_to_dir(path, ERROR_DIR, img)
                            continue

                        self.root.after(0, lambda f=img: self.log(f"\nğŸ§  [Track A] ì‹¬ì¸µ ë¶„ì„ ì‹œì‘: {f}"))
                        
                        try:
                            # 1. OCR & Hybrid Search Engine
                            search_text = gemini_api.get_pure_ocr_text(path)
                            final_score = 0.0
                            best_file = None
                            is_new_problem = False
                            
                            if self.vectorizer and search_text:
                                query_norm = self.normalize_text(search_text)
                                vec = self.vectorizer.transform([query_norm])
                                sims = cosine_similarity(vec, self.tfidf_matrix).flatten()
                                top_indices = sims.argsort()[-3:][::-1]
                                best_idx = top_indices[0]
                                base_score = sims[best_idx]
                                
                                ocr_nums = self.extract_numbers(search_text)
                                md_nums = self.md_numbers[best_idx]
                                num_bonus = 0.0
                                if ocr_nums and md_nums:
                                    intersection = ocr_nums.intersection(md_nums)
                                    recall = len(intersection) / len(ocr_nums)
                                    if recall >= 0.8: num_bonus = 0.3
                                    elif recall >= 0.5: num_bonus = 0.15
                                
                                final_score = base_score + num_bonus
                                best_file = self.md_files[best_idx]
                                self.log(f"ğŸ“Š ì ìˆ˜: Base({base_score:.2f}) + Bonus({num_bonus:.2f}) = {final_score:.2f}")

                                match_decision = "NEW"
                                if final_score >= 0.8: match_decision = "MATCH"
                                elif final_score >= 0.4:
                                    self.log(f"âš–ï¸ ì ìˆ˜ ì• ë§¤í•¨ ({final_score:.2f}). AI ì‹¬íŒê´€ ì†Œí™˜!")
                                    judge_candidates = []
                                    for idx in top_indices:
                                        judge_candidates.append((self.md_files[idx], self.md_contents[idx], sims[idx]))
                                    winner_idx = self.call_ai_judge(search_text, judge_candidates)
                                    if winner_idx != -1:
                                        best_file = judge_candidates[winner_idx][0]
                                        final_score = 0.99
                                        match_decision = "MATCH"
                                        self.log(f"ğŸ‰ AI ì‹¬íŒê´€ ë§¤ì¹­ í™•ì •: {best_file}")
                                    else:
                                        match_decision = "NEW"
                                        self.log("âš–ï¸ AI ì‹¬íŒê´€ íŒê²°: ì‹ ê·œ ìƒì„±")
                                else: match_decision = "NEW"

                                if match_decision == "MATCH":
                                    self.root.after(0, lambda f=best_file: self.log(f"ğŸ” [ë§¤ì¹­] ê¸°ì¡´ ë¬¸ì œ ì—…ë°ì´íŠ¸: {f}"))
                                    is_new_problem = False
                                else:
                                    self.root.after(0, lambda: self.log(f"ğŸ†• [ì‹ ê·œ] ìƒì„± ëª¨ë“œ"))
                                    is_new_problem = True
                            else:
                                is_new_problem = True

                            # 2. ë¶„ì„ (Forensic Mode)
                            self.root.after(0, lambda: self.log("ğŸ§  ìƒì„¸ ë¶„ì„ ì¤‘ (Tag Mode)..."))
                            json_data = gemini_api.analyze_image_structure(path)
                            if not json_data: 
                                self.root.after(0, lambda: self.log("âŒ ë¶„ì„ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨. ERROR ì´ë™."))
                                self.move_to_dir(path, ERROR_DIR, img)
                                continue
# [Robust Logic] ë¶€ëª¨ í´ë”ëª…ì„ ì¶”ì¶œí•˜ì—¬ íƒœê·¸ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
                            try:
                                # ğŸ‘‡ [ë””ë²„ê·¸ìš© ì¶”ê°€] ì´ ì¤„ì„ ë³µì‚¬í•´ì„œ ë¶™ì—¬ë„£ìœ¼ì„¸ìš” ğŸ‘‡
                                self.root.after(0, lambda p=path: self.log(f"ğŸ§­ [Tag Debug] path={p} | parent={os.path.basename(os.path.dirname(p))} | deep_root={os.path.basename(config.DEEP_WATCH_DIR)}"))
                                
                                parent_folder_path = os.path.dirname(path)
                                parent_folder_name = os.path.basename(parent_folder_path).strip()
                                
                                # ê°ì‹œ ë£¨íŠ¸ í´ë” ì´ë¦„ê³¼ ë‹¤ë¥´ê³ , ìœ íš¨í•œ ë¬¸ìì—´ì¼ ê²½ìš°ì—ë§Œ íƒœê·¸ë¡œ ì¸ì •
                                if parent_folder_name and parent_folder_name != os.path.basename(config.DEEP_WATCH_DIR):
                                    # json_data ë‚´ë¶€ì— db_columns êµ¬ì¡°ê°€ ì—†ìœ¼ë©´ ê°•ì œë¡œ ìƒì„±
                                    if "db_columns" not in json_data:
                                        json_data["db_columns"] = {}
                                    if "tags" not in json_data["db_columns"] or not isinstance(json_data["db_columns"]["tags"], list):
                                        json_data["db_columns"]["tags"] = []
                                    
                                    # ì¤‘ë³µ ë°©ì§€ í›„ íƒœê·¸ ì¶”ê°€
                                    if parent_folder_name not in json_data["db_columns"]["tags"]:
                                        json_data["db_columns"]["tags"].append(parent_folder_name)
                                        self.root.after(0, lambda tn=parent_folder_name: self.log(f"ğŸ·ï¸ [Auto Tag] í´ë”ëª… íƒœê·¸ ì¶”ê°€: {tn}"))
                            except Exception as e_tag:
                                self.root.after(0, lambda err=e_tag: self.log(f"âš ï¸ [Tag Error] í´ë” íƒœê·¸ ì¶”ê°€ ì‹¤íŒ¨ (ë¬´ì‹œí•˜ê³  ì§„í–‰): {err}"))
# â–²â–²â–² [ì—¬ê¸°ê¹Œì§€ ë¶™ì—¬ë„£ê¸°] â–²â–²â–²
                            # 3. ê°œë… ID ì¶”ì¶œ
                            detected_concept_ids = []
                            pcs = json_data.get("body_content", {}).get("practical_concepts", [])
                            
                            # [ì§„ë‹¨ìš© ë«] ë„ëŒ€ì²´ ë­ê°€ ë“¤ì–´ì˜¤ê³  ìˆëŠ”ì§€ í™•ì¸
                            self.root.after(0, lambda p=pcs: self.log(f"ğŸ§ª pcs type={type(p)}, sample0={type(p[0]) if isinstance(p, list) and p else None}"))
                            
                            for c in pcs:
                                if not isinstance(c, dict):
                                    self.root.after(0, lambda err=c: self.log(f"âš ï¸ [Loop Error] practical_concepts ìš”ì†Œ ë¶ˆëŸ‰: {type(err)} -> {err}"))
                                    continue
                                
                                self.process_single_concept(c) 
                                title_key = c.get('title', '').replace(" ", "")
                                if title_key in self.concept_map:
                                    detected_concept_ids.append(self.concept_map[title_key])

                            # 4. GitHub & URL
                            repo_idx = 4 
                            target_repo_path = config.LOCAL_REPO_PATHS[repo_idx]
                            target_repo_name = config.REPO_NAMES[repo_idx]
                            src_name = os.path.splitext(img)[0] if is_new_problem else os.path.splitext(best_file)[0]
                            safe_name = f"{src_name}{ext}".replace(" ", "_").replace("[", "").replace("]", "")
                            github_url = f"https://raw.githubusercontent.com/{config.GITHUB_USERNAME}/{target_repo_name}/main/{safe_name}"
                            
                            if "body_content" in json_data:
                                json_data["body_content"]["image_url"] = github_url
                                if is_new_problem: json_data["body_content"]["problem_text"] = search_text or "OCR í…ìŠ¤íŠ¸ ì—†ìŒ"
                                else:
                                    if "problem_text" in json_data["body_content"]: del json_data["body_content"]["problem_text"]
                                if not json_data["body_content"].get("verbatim_handwriting"):
                                    json_data["body_content"]["verbatim_handwriting"] = search_text or "OCR í…ìŠ¤íŠ¸ ì—†ìŒ"

                            # 5. Notion & MD Write (Mode Applied Here)
                            page_id = None
                            
                            # (A) ì‹ ê·œ ë¬¸ì œì¸ ê²½ìš° -> ë¬´ì¡°ê±´ ìƒì„±
                            if is_new_problem:
                                new_title = os.path.splitext(img)[0]
                                page_id, msg = notion_api.create_new_problem_page(new_title, json_data.get("db_columns", {}), detected_concept_ids)
                                if page_id:
                                    notion_api.append_children(page_id, json_data.get("body_content", {}))
                                    self.root.after(0, lambda t=new_title: self.log(f"âœ¨ [ìƒì„±] {t}"))
                                    
                                    # MD íŒŒì¼ ìƒì„±
                                    md_filename = f"{new_title}.md"
                                    md_path = os.path.join(config.MD_DIR_PATH, md_filename)
                                    ai_sol = json_data.get("body_content", {}).get("ai_solution", "í•´ì„¤ ì—†ìŒ")
                                    
                                    # [MD Logic: Append vs Overwrite]
                                    try:
                                        final_new = ""
                                        # ì´ì–´ ì“°ê¸° ëª¨ë“œ + íŒŒì¼ ì¡´ì¬
                                        if is_append_mode and os.path.exists(md_path):
                                            with open(md_path, 'r', encoding='utf-8') as f_read: current_content = f_read.read()
                                            # ë‚´ìš© í•˜ë‹¨ì— êµ¬ë¶„ì„  ë„£ê³  ì¶”ê°€
                                            final_new = current_content + "\n\n---\n## ğŸ§© [ì¶”ê°€ í•´ì„¤ / ê°•ì‚¬ í’€ì´]\n" + ai_sol
                                            self.root.after(0, lambda: self.log("ğŸ“ [Append] ê¸°ì¡´ íŒŒì¼ì— ë‚´ìš©ì„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤."))
                                        
                                        # ë®ì–´ ì“°ê¸° ëª¨ë“œ (ë˜ëŠ” ì‹ ê·œ íŒŒì¼)
                                        else:
                                            current_content = ""
                                            if os.path.exists(md_path):
                                                with open(md_path, 'r', encoding='utf-8') as f_read: current_content = f_read.read()
                                            
                                            # ê¸°ì¡´ íŒŒì¼ì˜ ì•ˆì „ ë§ˆì»¤ í™•ì¸
                                            if AI_SECTION_MARKER in current_content:
                                                final_new = current_content.split(AI_SECTION_MARKER)[0].rstrip() + AI_SECTION_MARKER + "\n" + ai_sol
                                                self.root.after(0, lambda: self.log(f"â™»ï¸ [ê°±ì‹ ] ê¸°ì¡´ ë¬¸ì œ ìœ ì§€, AI í•´ì„¤ë§Œ êµì²´"))
                                            elif current_content.strip() != "":
                                                final_new = current_content.rstrip() + AI_SECTION_MARKER + "\n" + ai_sol
                                                self.root.after(0, lambda: self.log(f"âš ï¸ [êµ¬ì¡°ë³€ê²½] ì•ˆì „ êµ¬ë¶„ì„  ì¶”ê°€"))
                                            else:
                                                final_new = "# " + str(new_title) + "\n\n## ë¬¸ì œ\n" + str(search_text) + "\n" + AI_SECTION_MARKER + "\n" + ai_sol
                                                self.root.after(0, lambda: self.log("ğŸ“ [ì‹ ê·œ] MD íŒŒì¼ ìƒì„±"))
                                                
                                        with open(md_path, "w", encoding="utf-8") as f_write: f_write.write(final_new)
                                    except Exception as e_md: self.log(f"âŒ MD ì‘ì„± ì˜¤ë¥˜: {e_md}")
                            
                            # (B) ê¸°ì¡´ ë¬¸ì œ ë§¤ì¹­ëœ ê²½ìš° -> Notion ì—…ë°ì´íŠ¸ & MD ëª¨ë“œ ì ìš©
                            else:
                                page_id, err = notion_api.find_page_id(best_file)
                                if page_id:
                                    notion_api.update_page_properties(page_id, json_data.get("db_columns", {}), concept_ids=detected_concept_ids)
                                    # Notionì€ ê¸°ë³¸ì ìœ¼ë¡œ Append ë°©ì‹
                                    notion_api.append_children(page_id, json_data.get("body_content", {}))
                                    self.root.after(0, lambda: self.log(f"âœ… Notion ì—…ë°ì´íŠ¸ ì™„ë£Œ"))
                                else:
                                    self.root.after(0, lambda: self.log(f"âŒ ë§¤ì¹­ ì‹¤íŒ¨: {err}"))
                                    self.move_to_dir(path, ERROR_DIR, img)
                                    continue

                            # 6. ë§ˆë¬´ë¦¬ (ì´ë™ & Git)
                            if page_id:
                                page_url = f"https://www.notion.so/{page_id.replace('-', '')}"
                                self.root.after(0, lambda t=src_name, u=page_url: self.add_history(f"âœ… {t}", u))
                                final_local_path = os.path.join(target_repo_path, safe_name)
                                try:
                                    shutil.move(path, final_local_path)
                                    self.git_push_updates(target_repo_path)
                                except Exception as e: self.log(f"âš  ì´ë™/ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
                            else:
                                self.move_to_dir(path, ERROR_DIR, img)

                        except Exception as e_inner:
                            self.root.after(0, lambda: self.log(f"ğŸ’£ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e_inner}"))
                            self.move_to_dir(path, ERROR_DIR, img)

                    # --------------------------------------------------------------
                    # [Timeout Check] íƒ€ì„ì•„ì›ƒëœ íŒŒì¼ ê°•ì œ ì²˜ë¦¬ (ë¡œì§ 100% ë³µì œ + Mode ì ìš©)
                    # --------------------------------------------------------------
                    expired_keys = []
                    for c_name, info in pending_queue.items():
                        if time.time() - info["timestamp"] > MERGE_WAIT_TIMEOUT:
                            expired_keys.append(c_name)
                    
                    for key in expired_keys:
                        info = pending_queue.pop(key)
                        self.log(f"â° [Timeout] {info['filename']} ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼! ë…ì ì²˜ë¦¬ ì‹œì‘.")
                        
                        # [DUPLICATED LOGIC START] - íƒ€ì„ì•„ì›ƒ íŒŒì¼ ì²˜ë¦¬ë¥¼ ìœ„í•´ ë¡œì§ ë°˜ë³µ (No Abstraction)
                        # ìœ„ì™€ ë™ì¼í•œ ë¡œì§ì´ íƒ€ì„ì•„ì›ƒëœ ë‹¨ì¼ íŒŒì¼(_1)ì—ë„ ì ìš©ë©ë‹ˆë‹¤.
                        path = info["path"]
                        img = info["filename"]
                        
                        # [NEW] Mode Check (Duplicated for Timeout)
                        is_append_mode = False
                        if any(trigger in img.lower() for trigger in ["_add", "_plus", "_append", "_added", "ì¶”ê°€"]):
                            is_append_mode = True
                            self.root.after(0, lambda: self.log(f"ğŸ“ [Mode] ì´ì–´ ì“°ê¸°(Append) - Timeout: {img}"))
                        else:
                            self.root.after(0, lambda: self.log(f"ğŸ“ [Mode] ë®ì–´ ì“°ê¸°(Overwrite) - Timeout: {img}"))

                        try:
                            # 1. OCR & Search
                            search_text = gemini_api.get_pure_ocr_text(path)
                            final_score = 0.0
                            best_file = None
                            is_new_problem = False
                            
                            if self.vectorizer and search_text:
                                query_norm = self.normalize_text(search_text)
                                vec = self.vectorizer.transform([query_norm])
                                sims = cosine_similarity(vec, self.tfidf_matrix).flatten()
                                top_indices = sims.argsort()[-3:][::-1]
                                best_idx = top_indices[0]
                                base_score = sims[best_idx]
                                ocr_nums = self.extract_numbers(search_text)
                                md_nums = self.md_numbers[best_idx]
                                num_bonus = 0.0
                                if ocr_nums and md_nums:
                                    intersection = ocr_nums.intersection(md_nums)
                                    recall = len(intersection) / len(ocr_nums)
                                    if recall >= 0.8: num_bonus = 0.3
                                    elif recall >= 0.5: num_bonus = 0.15
                                final_score = base_score + num_bonus
                                best_file = self.md_files[best_idx]
                                match_decision = "NEW"
                                if final_score >= 0.8: match_decision = "MATCH"
                                elif final_score >= 0.4:
                                    judge_candidates = []
                                    for idx in top_indices: judge_candidates.append((self.md_files[idx], self.md_contents[idx], sims[idx]))
                                    winner_idx = self.call_ai_judge(search_text, judge_candidates)
                                    if winner_idx != -1:
                                        best_file = judge_candidates[winner_idx][0]
                                        final_score = 0.99
                                        match_decision = "MATCH"
                                    else: match_decision = "NEW"
                                else: match_decision = "NEW"

                                if match_decision == "MATCH": is_new_problem = False
                                else: is_new_problem = True
                            else: is_new_problem = True

                            # 2. Analysis
                            json_data = gemini_api.analyze_image_structure(path)
                            if not json_data:
                                self.move_to_dir(path, ERROR_DIR, img)
                                continue
# [Robust Logic] íƒ€ì„ì•„ì›ƒëœ íŒŒì¼ íƒœê·¸ ì²˜ë¦¬
                            try:
                                # ğŸ‘‡ [ë””ë²„ê·¸ìš© ì¶”ê°€ 2] ì—¬ê¸°ë„ ë˜‘ê°™ì´ ë¶™ì—¬ë„£ìœ¼ì„¸ìš” ğŸ‘‡
                                self.root.after(0, lambda p=path: self.log(f"ğŸ§­ [Tag Debug-Timeout] path={p} | parent={os.path.basename(os.path.dirname(p))} | deep_root={os.path.basename(config.DEEP_WATCH_DIR)}"))
                                
                                parent_folder_path_to = os.path.dirname(path)
                                parent_folder_name_to = os.path.basename(parent_folder_path_to).strip()
                                
                                if parent_folder_name_to and parent_folder_name_to != os.path.basename(config.DEEP_WATCH_DIR):
                                    if "db_columns" not in json_data:
                                        json_data["db_columns"] = {}
                                    if "tags" not in json_data["db_columns"] or not isinstance(json_data["db_columns"]["tags"], list):
                                        json_data["db_columns"]["tags"] = []
                                    
                                    if parent_folder_name_to not in json_data["db_columns"]["tags"]:
                                        json_data["db_columns"]["tags"].append(parent_folder_name_to)
                                        self.root.after(0, lambda tn=parent_folder_name_to: self.log(f"ğŸ·ï¸ [Auto Tag-Timeout] í´ë”ëª… íƒœê·¸ ì¶”ê°€: {tn}"))
                            except Exception as e_tag_to:
                                self.root.after(0, lambda err=e_tag_to: self.log(f"âš ï¸ [Tag Error-Timeout] í´ë” íƒœê·¸ ì¶”ê°€ ì‹¤íŒ¨ (ë¬´ì‹œí•˜ê³  ì§„í–‰): {err}"))
# â–²â–²â–² [ì—¬ê¸°ê¹Œì§€ ë¶™ì—¬ë„£ê¸°] â–²â–²â–²
                            # 3. Concept ID
                            detected_concept_ids = []
                            pcs = json_data.get("body_content", {}).get("practical_concepts", [])
                            
                            # [ì§„ë‹¨ìš© ë«] ë„ëŒ€ì²´ ë­ê°€ ë“¤ì–´ì˜¤ê³  ìˆëŠ”ì§€ í™•ì¸
                            self.root.after(0, lambda p=pcs: self.log(f"ğŸ§ª pcs type={type(p)}, sample0={type(p[0]) if isinstance(p, list) and p else None}"))
                            
                            for c in pcs:
                                if not isinstance(c, dict):
                                    self.root.after(0, lambda err=c: self.log(f"âš ï¸ [Loop Error] practical_concepts ìš”ì†Œ ë¶ˆëŸ‰: {type(err)} -> {err}"))
                                    continue
                                
                                self.process_single_concept(c) 
                                title_key = c.get('title', '').replace(" ", "")
                                if title_key in self.concept_map:
                                    detected_concept_ids.append(self.concept_map[title_key])

                            # 4. GitHub
                            repo_idx = 4 
                            target_repo_path = config.LOCAL_REPO_PATHS[repo_idx]
                            target_repo_name = config.REPO_NAMES[repo_idx]
                            _, ext = os.path.splitext(img)
                            src_name = os.path.splitext(img)[0] if is_new_problem else os.path.splitext(best_file)[0]
                            safe_name = f"{src_name}{ext}".replace(" ", "_").replace("[", "").replace("]", "")
                            github_url = f"https://raw.githubusercontent.com/{config.GITHUB_USERNAME}/{target_repo_name}/main/{safe_name}"
                            if "body_content" in json_data:
                                json_data["body_content"]["image_url"] = github_url
                                if is_new_problem: json_data["body_content"]["problem_text"] = search_text or "OCR í…ìŠ¤íŠ¸ ì—†ìŒ"
                                else: 
                                    if "problem_text" in json_data["body_content"]: del json_data["body_content"]["problem_text"]
                                if not json_data["body_content"].get("verbatim_handwriting"):
                                    json_data["body_content"]["verbatim_handwriting"] = search_text or "OCR í…ìŠ¤íŠ¸ ì—†ìŒ"

                            # 5. Notion & MD (Timeout Branch - Mode Logic Duplicated)
                            page_id = None
                            if is_new_problem:
                                new_title = os.path.splitext(img)[0]
                                page_id, msg = notion_api.create_new_problem_page(new_title, json_data.get("db_columns", {}), detected_concept_ids)
                                if page_id:
                                    notion_api.append_children(page_id, json_data.get("body_content", {}))
                                    self.root.after(0, lambda t=new_title: self.log(f"âœ¨ [Timeout] ìƒì„±: {t}"))
                                    
                                    # MD ìƒì„± ë¡œì§
                                    md_filename = f"{new_title}.md"
                                    md_path = os.path.join(config.MD_DIR_PATH, md_filename)
                                    ai_sol = json_data.get("body_content", {}).get("ai_solution", "í•´ì„¤ ì—†ìŒ")
                                    try:
                                        final_new = ""
                                        # Append Logic
                                        if is_append_mode and os.path.exists(md_path):
                                            with open(md_path, 'r', encoding='utf-8') as f_read: current_content = f_read.read()
                                            final_new = current_content + "\n\n---\n## ğŸ§© [ì¶”ê°€ í•´ì„¤ / ê°•ì‚¬ í’€ì´]\n" + ai_sol
                                            self.root.after(0, lambda: self.log("ğŸ“ [Append] ë‚´ìš© ì¶”ê°€ë¨ (Timeout)"))
                                        # Overwrite Logic
                                        else:
                                            current_content = ""
                                            if os.path.exists(md_path):
                                                with open(md_path, 'r', encoding='utf-8') as f_read: current_content = f_read.read()
                                            if AI_SECTION_MARKER in current_content:
                                                final_new = current_content.split(AI_SECTION_MARKER)[0].rstrip() + AI_SECTION_MARKER + "\n" + ai_sol
                                            elif current_content.strip() != "":
                                                final_new = current_content.rstrip() + AI_SECTION_MARKER + "\n" + ai_sol
                                            else:
                                                final_new = "# " + str(new_title) + "\n\n## ë¬¸ì œ\n" + str(search_text) + "\n" + AI_SECTION_MARKER + "\n" + ai_sol
                                        
                                        with open(md_path, "w", encoding="utf-8") as f_write: f_write.write(final_new)
                                    except: pass
                            else:
                                page_id, err = notion_api.find_page_id(best_file)
                                if page_id:
                                    notion_api.update_page_properties(page_id, json_data.get("db_columns", {}), concept_ids=detected_concept_ids)
                                    notion_api.append_children(page_id, json_data.get("body_content", {}))
                                    self.root.after(0, lambda: self.log(f"âœ… [Timeout] ì—…ë°ì´íŠ¸ ì™„ë£Œ"))
                                else:
                                    self.move_to_dir(path, ERROR_DIR, img)
                                    continue

                            # 6. Finish
                            if page_id:
                                final_local_path = os.path.join(target_repo_path, safe_name)
                                try:
                                    shutil.move(path, final_local_path)
                                    self.git_push_updates(target_repo_path)
                                except: pass
                            else:
                                self.move_to_dir(path, ERROR_DIR, img)

                        except Exception as e_inner_to:
                            self.log(f"ğŸ’£ Timeout íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e_inner_to}")
                            self.move_to_dir(path, ERROR_DIR, img)
                        # [DUPLICATED LOGIC END]

                # ==================================================================================
                # [Track B] ìë£Œ ìˆ˜ì§‘ ëª¨ë“œ (ê¸°ì¡´ ë¡œì§ 100% ìœ ì§€)
                # ==================================================================================
                if os.path.exists(config.FAST_WATCH_DIR):
                    for root, dirs, files in os.walk(config.FAST_WATCH_DIR):
                        if files: processed_any = True
                        for file in files:
                            if not self.is_running: break
                            
                            if "_Q." in file and file.lower().endswith(('.png', '.jpg', '.jpeg')):
                                q_path = os.path.join(root, file)
                                try:
                                    sz1 = os.path.getsize(q_path); time.sleep(0.5)
                                    if sz1 != os.path.getsize(q_path): continue
                                except: continue

                                a_filename = file.replace("_Q.", "_A.")
                                a_path = os.path.join(root, a_filename)
                                has_answer = False
                                if os.path.exists(a_path):
                                    try:
                                        sz_a1 = os.path.getsize(a_path); time.sleep(0.5)
                                        if sz_a1 != os.path.getsize(a_path): continue 
                                        has_answer = True
                                    except: pass
                                
# [ì´ ì¤„ê³¼ ë¼ì¸ì„ ë§ì¶”ì„¸ìš”]
                                self.root.after(0, lambda f=file: self.log(f"âš¡ [Track B] ìˆ˜ì§‘ ì‹œì‘: {f}"))

# â–¼â–¼â–¼ [ì—¬ê¸°ì„œë¶€í„° ë¶™ì—¬ë„£ê¸°] ì‹œì‘ ë¶€ë¶„(current_folder_name)ì´ ìœ—ì¤„ self.root.afterì™€ ì¤„ì´ ë”± ë§ì•„ì•¼ í•©ë‹ˆë‹¤ â–¼â–¼â–¼
                                # [Robust Logic] í´ë”ëª…ì„ ë¶„ì„í•˜ì—¬ ì‘ë™ ëª¨ë“œë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
                                current_folder_name = os.path.basename(root)
                                is_tag_update_mode = current_folder_name.endswith("_íƒœê·¸ì¶”ê°€")
                                
                                if is_tag_update_mode:
                                    # ----------------------------------------------------------------------
                                    # [MODE 1: íƒœê·¸ ì—…ë°ì´íŠ¸ ì „ìš© ëª¨ë“œ]
                                    # ----------------------------------------------------------------------
                                    tag_to_add = current_folder_name.replace("_íƒœê·¸ì¶”ê°€", "").strip()
                                    self.root.after(0, lambda t=tag_to_add: self.log(f"ğŸ”„ [Update Mode] íƒœê·¸ ì¶”ê°€ ì „ìš© ëª¨ë“œ ì§„ì…. ëŒ€ìƒ íƒœê·¸: '{t}'"))

                                    try:
                                        q_text_search = gemini_api.get_pure_ocr_text(q_path)
                                        if not q_text_search or not self.vectorizer:
                                            raise Exception("OCR ì‹¤íŒ¨ ë˜ëŠ” ê²€ìƒ‰ ì—”ì§„ ë¯¸ì¤€ë¹„ë¡œ ê²€ìƒ‰ ë¶ˆê°€")

                                        # [ê²€ìƒ‰ ì—”ì§„ ê°€ë™]
                                        query_norm = self.normalize_text(q_text_search)
                                        vec = self.vectorizer.transform([query_norm])
                                        sims = cosine_similarity(vec, self.tfidf_matrix).flatten()
                                        top_indices = sims.argsort()[-3:][::-1]
                                        
                                        best_match_file = None
                                        match_found = False

                                        best_idx_candidate = top_indices[0]
                                        base_score = sims[best_idx_candidate]

                                        # ë²ˆí˜¸ ì¼ì¹˜ ë³´ë„ˆìŠ¤
                                        ocr_nums = self.extract_numbers(q_text_search)
                                        md_nums = self.md_numbers[best_idx_candidate]
                                        num_bonus = 0.0
                                        if ocr_nums and md_nums:
                                            intersection = ocr_nums.intersection(md_nums)
                                            recall = len(intersection) / len(ocr_nums)
                                            if recall >= 0.8: num_bonus = 0.3
                                            elif recall >= 0.5: num_bonus = 0.15
                                        
                                        final_score_candidate = base_score + num_bonus

                                        # ë§¤ì¹­ íŒì •
                                        if final_score_candidate >= 0.8:
                                            best_match_file = self.md_files[best_idx_candidate]
                                            match_found = True
                                            self.log(f"ğŸ¯ [ê²€ìƒ‰ ì„±ê³µ] ê³ ë“ì  ë§¤ì¹­: {best_match_file} (Score: {final_score_candidate:.2f})")
                                        elif final_score_candidate >= 0.4:
                                            self.log(f"âš–ï¸ [ê²€ìƒ‰ ì• ë§¤] AI ì‹¬íŒê´€ ì†Œí™˜ (Score: {final_score_candidate:.2f})")
                                            judge_candidates = []
                                            for idx in top_indices:
                                                judge_candidates.append((self.md_files[idx], self.md_contents[idx], sims[idx]))
                                            winner_idx = self.call_ai_judge(q_text_search, judge_candidates)
                                            if winner_idx != -1:
                                                best_match_file = judge_candidates[winner_idx][0]
                                                match_found = True
                                                self.log(f"ğŸ‰ [AI ì‹¬íŒê´€] ë§¤ì¹­ í™•ì •: {best_match_file}")
                                            else:
                                                self.log("âš–ï¸ [AI ì‹¬íŒê´€] ë¶ˆì¼ì¹˜ íŒì •.")

                                        # ê²°ê³¼ ì²˜ë¦¬
                                        if match_found and best_match_file and tag_to_add:
                                            page_id_target, err_target = notion_api.find_page_id(best_match_file)
                                            if page_id_target:
                                                update_payload = {"tags": [tag_to_add]}
                                                notion_api.update_page_properties(page_id_target, update_payload)
                                                self.log(f"âœ… [íƒœê·¸ ì—…ë°ì´íŠ¸] {best_match_file} -> '{tag_to_add}'")

                                                relative_path = os.path.relpath(root, config.FAST_WATCH_DIR)
                                                target_dir = os.path.join(COMPLETED_DIR, "[2]_ìë£Œìˆ˜ì§‘_Fast_Updated", relative_path)
                                                if not os.path.exists(target_dir): os.makedirs(target_dir)
                                                shutil.move(q_path, os.path.join(target_dir, file))
                                                if has_answer: shutil.move(a_path, os.path.join(target_dir, a_filename))
                                                self.log(f"ğŸ“¦ ì™„ë£Œ í´ë”(_Updated)ë¡œ ì´ë™ë¨.")
                                            else:
                                                self.log(f"âŒ [Notion 404] í˜ì´ì§€ ëª» ì°¾ìŒ: {err_target}")
                                        else:
                                            self.log(f"ğŸš« [ì—…ë°ì´íŠ¸ ìŠ¤í‚µ] DB ë§¤ì¹­ ì‹¤íŒ¨. (íŒŒì¼ ìœ ì§€)")

                                    except Exception as e_update:
                                        self.log(f"ğŸ’£ [Update Error] {e_update}")
                                        self.move_to_dir(q_path, ERROR_DIR, file)
                                        if has_answer: self.move_to_dir(a_path, ERROR_DIR, a_filename)

                                else:
                                    # ----------------------------------------------------------------------
                                    # [MODE 2: ì‹ ê·œ ìƒì„± ëª¨ë“œ]
                                    # ----------------------------------------------------------------------
                                    try:
                                        q_text = gemini_api.get_pure_ocr_text(q_path) or "OCR ì‹¤íŒ¨"
                                        a_text = ""
                                        if has_answer: a_text = gemini_api.get_pure_ocr_text(a_path) or "OCR ì‹¤íŒ¨"

                                        folder_name = current_folder_name 
                                        if folder_name == os.path.basename(config.FAST_WATCH_DIR): folder_name = "ë¯¸ë¶„ë¥˜"
                                        
                                        import category_manager
                                        suggested_tags = category_manager.get_suggested_tags(folder_name, q_text)
                                        final_tags = list(dict.fromkeys([folder_name, "ê¸°ì¶œë¬¸ì œ"] + suggested_tags))
                                        # [Robust Logic 1] Aë‹¨ê³„(ë‹¨ìˆœê³„ì‚°) íƒœê·¸ ìë™ ë¶€ì°©
                                        is_basic = False
                                        try:
                                            if gemini_api.check_is_basic_drill(q_text):
                                                final_tags.append("#ë‹¨ìˆœê³„ì‚°")
                                                is_basic = True
                                                self.log(f"ğŸ·ï¸ [Auto Tag] ë‹¨ìˆœ ê³„ì‚° ë¬¸ì œ ê°ì§€ -> '#ë‹¨ìˆœê³„ì‚°'")
                                        except: pass

                                        # [Robust Logic 2] ì‹œëŒ€ì¸ì¬ê¸‰ ë‚œì´ë„ íƒœê·¸ ìë™ ë¶€ì°© (ë‹¨ìˆœê³„ì‚° ì•„ë‹ ë•Œë§Œ)
                                        if not is_basic:
                                            try:
                                                diff_tag = gemini_api.analyze_difficulty_level(q_text)
                                                final_tags.append(f"#{diff_tag}")
                                                self.log(f"ğŸ·ï¸ [Auto Tag] ë‚œì´ë„ íŒë… -> '#{diff_tag}'")
                                            except: pass

                                        # [Robust Logic 3] ì •ë‹µ ì¶”ì¶œê¸° (Regex Hunter)
                                        extracted_answer = ""
                                        if has_answer and a_text:
                                            try:
                                                # ì „ëµ 1: ëª…ì‹œì  í‚¤ì›Œë“œ ê²€ìƒ‰
                                                match = re.search(r'(?:ì •ë‹µ|ë‹µ)\s*[:\-\.]?\s*(\d+|[â‘ -â‘¤]|[a-zA-Z]+)', a_text)
                                                if match: extracted_answer = match.group(1)
                                                else:
                                                    # ì „ëµ 2: í…ìŠ¤íŠ¸ê°€ ë§¤ìš° ì§§ìœ¼ë©´ ì „ì²´ë¥¼ ì •ë‹µìœ¼ë¡œ ê°„ì£¼
                                                    clean_a = a_text.strip()
                                                    if len(clean_a) < 10 and any(c.isdigit() for c in clean_a): extracted_answer = clean_a
                                                    else:
                                                        # ì „ëµ 3: ë§ˆì§€ë§‰ ì¤„ì—ì„œ ìˆ«ì ì°¾ê¸°
                                                        lines = clean_a.split('\n')
                                                        last_line = lines[-1].strip()
                                                        num_match = re.search(r'(\d+)', last_line)
                                                        if num_match: extracted_answer = num_match.group(1)
                                            except: pass
                                        q_name_base = os.path.splitext(file)[0].replace("_Q", "")
                                        db_data = {
                                            "main_category": folder_name, "tags": final_tags,
                                            "necessity": "", "key_idea": "", "special_point": "", "source": q_name_base,
                                            "correct_answer": extracted_answer # [NEW] ì •ë‹µ í•„ë“œ ì¶”ê°€
                                        }
                                        
                                        page_id, msg = notion_api.create_new_problem_page(q_name_base, db_data)
                                        
                                        if page_id:
                                            body_content = {
                                                "problem_text": q_text,
                                                "ai_solution": f"## í•´ì„¤\n{a_text}" if a_text else "í•´ì„¤ ì—†ìŒ",
                                                "verbatim_handwriting": "Track B ìë™ ìˆ˜ì§‘ ëª¨ë“œ", "image_url": ""
                                            }
                                            notion_api.append_children(page_id, body_content)
                                            
                                            current_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                                            md_content = f"""---
type: collection
id: {q_name_base}
category: {folder_name}
tags: {json.dumps(final_tags, ensure_ascii=False)}
date: {current_time_str}
---

# {q_name_base}

## ë¬¸ì œ
![problem]({file})

{q_text}

## í•´ì„¤
![solution]({a_filename})

{a_text}
"""
                                            md_save_path = os.path.join(config.MD_DIR_PATH, f"{q_name_base}.md")
                                            with open(md_save_path, "w", encoding="utf-8") as f: f.write(md_content)
                                                
                                            relative_path = os.path.relpath(root, config.FAST_WATCH_DIR)
                                            target_dir = os.path.join(COMPLETED_DIR, "[2]_ìë£Œìˆ˜ì§‘_Fast", relative_path)
                                            if not os.path.exists(target_dir): os.makedirs(target_dir)

                                            shutil.move(q_path, os.path.join(target_dir, file))
                                            if has_answer: shutil.move(a_path, os.path.join(target_dir, a_filename))
                                                
                                            page_url = f"https://www.notion.so/{page_id.replace('-', '')}"
                                            self.root.after(0, lambda t=q_name_base: self.log(f"âœ… [Track B] ì‹ ê·œ ìƒì„± ì™„ë£Œ: {t}"))
                                            self.add_history(f"ğŸ“¦ [ìˆ˜ì§‘] {q_name_base}", page_url)
                                            time.sleep(3)
                                        else:
                                            self.root.after(0, lambda s=msg: self.log(f"âŒ [Notion Fail] {s}"))
                                            self.move_to_dir(q_path, ERROR_DIR, file)
                                            if has_answer: self.move_to_dir(a_path, ERROR_DIR, a_filename)

                                    except Exception as e_b:
                                        self.root.after(0, lambda err=e_b: self.log(f"ğŸ’£ [Track B Error] {err}"))
                                        self.move_to_dir(q_path, ERROR_DIR, file)
                                        if has_answer: self.move_to_dir(a_path, ERROR_DIR, a_filename)
# â–²â–²â–² [ì—¬ê¸°ê¹Œì§€ ë¶™ì—¬ë„£ê¸°] â–²â–²â–²
                
                # ------------------------------------------------------------------
                # [Main Track 2] ì‹¤ì „ê°œë… ì´ë¯¸ì§€ ì²˜ë¦¬ (Concept Track - ê¸°ì¡´ ë¡œì§ 100% ìœ ì§€)
                # ------------------------------------------------------------------
                if not self.is_running: break

                files_concept = [f for f in os.listdir(config.CONCEPT_WATCH_FOLDER) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]
                
                if files_concept:
                    processed_any = True
                    for img in files_concept:
                        if not self.is_running: break
                        path = os.path.join(config.CONCEPT_WATCH_FOLDER, img)
                        repo_idx = 4
                        target_repo_path = config.LOCAL_REPO_PATHS[repo_idx]
                        target_repo_name = config.REPO_NAMES[repo_idx]
                        _, ext = os.path.splitext(img)
                        try:
                            result_json = gemini_api.extract_concepts_flexible(path)
                            if result_json and "concepts" in result_json:
                                for c in result_json["concepts"]:
                                    title = c.get('title', 'ì œëª©ì—†ìŒ')
                                    safe_title = "".join([x for x in title if x.isalnum() or x in (' ', '_', '-')]).strip()
                                    safe_name = f"[ê°œë…]_{safe_title}{ext}".replace(" ", "_")
                                    github_url = f"https://raw.githubusercontent.com/{config.GITHUB_USERNAME}/{target_repo_name}/main/{safe_name}"
                                    self.process_single_concept(c, github_url)
                                
                                final_local_path = os.path.join(target_repo_path, safe_name)
                                try:
                                    shutil.move(path, final_local_path)
                                    self.root.after(0, lambda f=safe_name: self.log(f"âœ… [ê°œë…] {f} ì™„ë£Œ"))
                                    self.root.after(0, self.update_concept_list)
                                except: pass
                            else:
                                self.move_to_dir(path, ERROR_DIR, img)
                        except Exception as e:
                            self.move_to_dir(path, ERROR_DIR, img)
                
                if processed_any:
                    time.sleep(0.1) # íŒŒì¼ ê°ì§€ ì‹œ ì¦‰ì‹œ ì¬ìŠ¤ìº” (CPU í­ì£¼ ë°©ì§€ ìµœì†Œ ì¿¨íƒ€ì„)
                else:
                    time.sleep(2) # ìœ íœ´ ì‹œ CPU íœ´ì‹

        except Exception as e:
            error_msg = f"ìŠ¤ë ˆë“œ ì¹˜ëª…ì  ì¶©ëŒ:\n{e}"
            print(error_msg)
            self.root.after(0, lambda: messagebox.showerror("ì‹œìŠ¤í…œ ì˜¤ë¥˜", error_msg))
        
        finally:
            self.is_running = False
            self.root.after(0, lambda: self.btn_run.config(state="normal", text="â–¶ ìë™í™” ì‹œì‘", bg="#4CAF50"))
            self.root.after(0, lambda: self.lbl_status.config(text="ëŒ€ê¸° ì¤‘ (ë£¨í”„ ì •ì§€ë¨)", fg="black"))
    # â–²â–²â–²â–²â–² [ì—¬ê¸°ê¹Œì§€ êµì²´] â–²â–²â–²â–²â–²
    # â–²â–²â–²â–²â–² [ì—¬ê¸°ê¹Œì§€ êµì²´] â–²â–²â–²â–²â–²
    # â–²â–²â–²â–²â–² [ì—¬ê¸°ê¹Œì§€ ë³µì‚¬] â–²â–²â–²â–²â–²
    # â–²â–²â–²â–²â–² [ì—¬ê¸°ê¹Œì§€ ë³µì‚¬] â–²â–²â–²â–²â–²
    # â–²â–²â–²â–²â–² [ì—¬ê¸°ê¹Œì§€ êµì²´] â–²â–²â–²â–²â–²

    def process_single_concept(self, concept_data, image_url=None):
        if not isinstance(concept_data, dict):
            self.root.after(0, lambda d=concept_data: self.log(f"âš ï¸ [Type Error] process_single_concept ì…ë ¥ì´ dict ì•„ë‹˜: {type(d)} -> {d}"))
            return None
        # 1. ë¡œì»¬ ì €ì¥ (ë‚´ë¶€ ì¥ë¶€ ê¸°ë¡ - ë¦¬ìŠ¤íŠ¸ í‘œì‹œìš©)
        concept_manager.save_concept(concept_data)
        
        # 2. Notion ë™ê¸°í™” (ëˆ„ë½ëœ 'ë³´ê³  ì²´ê³„' ë³µêµ¬)
        # ë¡œì»¬ì— ì €ì¥ëœ ë‚´ìš©ì„ Notion ì‹¤ì „ê°œë… DBë¡œ ì¦‰ì‹œ ì „ì†¡í•©ë‹ˆë‹¤.
        try:
            title = concept_data.get('title', 'ì œëª©ì—†ìŒ')
            content = concept_data.get('content', '')
            
            # concept_sync.pyì— ìˆëŠ” ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ (ì´ë¯¸ì§€ URL í¬í•¨)
            # ì´ì œ MathBotì´ í˜¼ìë§Œ ì•Œì§€ ì•Šê³  Notionì— ë³´ê³ í•©ë‹ˆë‹¤.
            if hasattr(concept_sync, 'create_concept_page'):
                page_id = concept_sync.create_concept_page(concept_data, image_url)
                
                if page_id:
                    # ì „ì†¡ ì„±ê³µ ì‹œ ë§¤í•‘ í…Œì´ë¸”(ì œëª©->ID) ê°±ì‹ 
                    self.concept_map[title.replace(" ", "")] = page_id
                    self.root.after(0, lambda: self.log(f"ğŸ“¡ [Sync] ë…¸ì…˜ ì—…ë¡œë“œ ì„±ê³µ: {title}"))
                else:
                    self.root.after(0, lambda: self.log(f"âš ï¸ [Sync] ë…¸ì…˜ ì—…ë¡œë“œ ì‹¤íŒ¨ (ID ë°˜í™˜ ì—†ìŒ): {title}"))
            else:
                # í˜¹ì‹œ í•¨ìˆ˜ ì´ë¦„ì´ ë‹¤ë¥¼ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ì˜ˆì™¸ ì²˜ë¦¬
                self.root.after(0, lambda: self.log("âš ï¸ [System] concept_sync.create_concept_page í•¨ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."))
                
        except Exception as e:
            self.root.after(0, lambda err=e: self.log(f"âŒ [Sync Error] ì‹¤ì „ê°œë… ë™ê¸°í™” ì¤‘ ì˜¤ë¥˜: {err}"))

if __name__ == "__main__":
    backup_main_source_phase2()
    root = tk.Tk()
    app = AutoMathBot(root)
    root.mainloop()
